{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobassir94/Multilingual-Speech-to-Speech-Translator/blob/main/E2E_Single_Sample_Demo_of_Multilingual_Speech_to_Speech_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li2HzcUKBdhF"
      },
      "source": [
        "Authors,\n",
        "\n",
        "*   Md. Nazmuddhoha Ansary (Ansary)\n",
        "*   Syed Mobassir (Shabab)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37jVRx95QwDv"
      },
      "source": [
        "# install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kwFbJHWW2a1o"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install pytube==12.1.0\n",
        "!pip install pydub==0.25.1\n",
        "\n",
        "!pip install -q transformers==4.24.0\n",
        "\n",
        "!pip install sentencepiece==0.1.97\n",
        "!pip install git+https://github.com/csebuetnlp/normalizer\n",
        "\n",
        "# !pip install ffmpeg==1.4\n",
        "!pip install ffmpeg-python==0.2.0\n",
        "\n",
        "#! pip install -U pip\n",
        "! pip install TTS==0.8.0\n",
        "! pip install bnnumerizer==0.0.2\n",
        "! pip install bangla==0.0.2\n",
        "! pip install gdown==4.5.1\n",
        "! pip install bnunicodenormalizer==0.1.1\n",
        "! pip install PyArabic==0.6.15\n",
        "#! pip install pydub\n",
        "! pip install Unidecode==1.3.6\n",
        "#! pip install numpy\n",
        "!pip install pydload==1.0.9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RutPYk_RQzgr"
      },
      "source": [
        "# Cool Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co7k3t422xmv",
        "outputId": "61a888d2-4d79-4825-85e7-c806d1ebfa95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:25<00:00, 119MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pytube\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import re\n",
        "import whisper\n",
        "import librosa\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "import shutil\n",
        "import ffmpeg\n",
        "from IPython.display import Audio \n",
        "\n",
        "import torch\n",
        "import bangla\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n",
        "\n",
        "\n",
        "model = whisper.load_model(\"large\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfQvVwPMQ3zp"
      },
      "source": [
        "# Download single youtube video and convert that into .wav file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uoalO1hBvkNI",
        "outputId": "be58d8bc-beed-42b4-aa4f-02fe65fa225d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/The Dangers of Showing Off  Shaykh Dr Yasir Qadhi.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#https://towardsdatascience.com/speech-to-text-with-openais-whisper-53d5cea9005e\n",
        "\n",
        "# Reading from Youtube video link\n",
        "video = 'https://www.youtube.com/watch?v=GmQo2kTbZc0'\n",
        "data = pytube.YouTube(video)\n",
        "# Converting and downloading as 'MP4' file\n",
        "audio = data.streams.get_audio_only()\n",
        "audio.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXVsJB4C5TkG",
        "outputId": "753e45ac-cce1-4ec7-86d8-02de664bfc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/The Dangers of Showing Off  Shaykh Dr Yasir Qadhi.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    creation_time   : 2022-07-07T22:24:04.000000Z\n",
            "  Duration: 00:05:13.19, start: 0.000000, bitrate: 129 kb/s\n",
            "    Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 4 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-07-07T22:24:04.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to './en_ar_lecture.wav':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    ISFT            : Lavf57.83.100\n",
            "    Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-07-07T22:24:04.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      encoder         : Lavc57.107.100 pcm_s16le\n",
            "size=   53952kB time=00:05:13.19 bitrate=1411.2kbits/s speed= 818x    \n",
            "video:0kB audio:53952kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000141%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!ffmpeg -i '/content/The Dangers of Showing Off  Shaykh Dr Yasir Qadhi.mp4' -ac 2 -f wav './en_ar_lecture.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cZhkOn6TxgCW"
      },
      "outputs": [],
      "source": [
        "# #https://stackoverflow.com/questions/47420304/download-video-in-mp3-format-using-pytube\n",
        "\n",
        "# from pytube.cli import on_progress\n",
        "\n",
        "# PATH_SAVE = \"./\"\n",
        "\n",
        "\n",
        "# yt = pytube.YouTube('https://www.youtube.com/watch?v=g8YHuKn5NpY', on_progress_callback=on_progress)\n",
        "# #Download mp3\n",
        "# audio_file = yt.streams.filter(only_audio=True).first().download(PATH_SAVE)\n",
        "# base, ext = os.path.splitext(audio_file)\n",
        "# new_file = base + '.wav'\n",
        "# os.rename(audio_file, new_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lmya3trey9VZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Audio('/content/abc.wav', autoplay=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKtyHFGRMgC2"
      },
      "source": [
        "# STEP-1 : Multilingual Speech to Text Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LP4A0Ssw1Ex8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def collapse_whitespace(text):\n",
        "    # Regular expression matching whitespace:\n",
        "    _whitespace_re = re.compile(r\"\\s+\")\n",
        "    return re.sub(_whitespace_re, \" \", text)\n",
        "\n",
        "def mlt_speech_to_text_convertor(path = \"seerah_of_the_prophet.wav\",silence_based_conversion = False):\n",
        "    '''\n",
        "        #modified from https://www.geeksforgeeks.org/python-speech-recognition-on-large-audio-files/\n",
        "\n",
        "        -> a function that splits the audio file into chunks and applies multilingual speech recognition.\n",
        "        -> supports both silence_based_conversion and fixed length chunking\n",
        "    '''\n",
        "    shutil.rmtree('audio_chunks', ignore_errors=True)\n",
        "    # create a directory to store the audio chunks.\n",
        "    try:\n",
        "        os.mkdir('audio_chunks')\n",
        "    except(FileExistsError):\n",
        "        pass\n",
        "  \n",
        "    # move into the directory to\n",
        "    # store the audio files.\n",
        "    os.chdir('audio_chunks')\n",
        "    \n",
        "\n",
        "    if(not silence_based_conversion):\n",
        "        full_audio, fs = librosa.load(path)\n",
        "        TEXTS=[]\n",
        "        MAX_AUDIO_LEN=30*fs\n",
        "        for idx in range(0,full_audio.shape[0],MAX_AUDIO_LEN):\n",
        "          audio=full_audio[idx:idx+MAX_AUDIO_LEN]\n",
        "          sf.write(f\"{idx}.wav\",audio,fs)\n",
        "          audio = whisper.load_audio(f\"{idx}.wav\")\n",
        "          audio = whisper.pad_or_trim(audio)\n",
        "          # make log-Mel spectrogram and move to the same device as the model\n",
        "          mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "          # decode the audio\n",
        "          options = whisper.DecodingOptions()\n",
        "          result = whisper.decode(model, mel, options)\n",
        "      \n",
        "          #take only arabic and english\n",
        "          result=re.sub('[^\\u0600-\\u06FF a-zA-Z0-9,?!.\\']',' ',result.text)\n",
        "          result = collapse_whitespace(result)\n",
        "          \n",
        "          # print the recognized text\n",
        "          TEXTS.append(result)\n",
        "        os.chdir('..')\n",
        "        shutil.rmtree('audio_chunks', ignore_errors=True)\n",
        "        return TEXTS\n",
        "\n",
        "    # open the audio file stored in\n",
        "    # the local system as a wav file.\n",
        "    lecture = AudioSegment.from_wav(path)\n",
        "\n",
        "    # split track where silence is 1 seconds \n",
        "    # or more and get chunks\n",
        "    chunks = split_on_silence(lecture,\n",
        "        # must be silent for at least half seconds\n",
        "        # or 1000 ms. adjust this value based on user\n",
        "        # requirement. if the speaker stays silent for \n",
        "        # longer, increase this value. else, decrease it.\n",
        "        min_silence_len = 500,\n",
        "  \n",
        "        # consider it silent if quieter than -16 dBFS\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = -16\n",
        "    )\n",
        "  \n",
        "  \n",
        "    TEXTS=[]\n",
        "    i = 0\n",
        "    # process each chunk\n",
        "    for chunk in chunks:\n",
        "              \n",
        "        # duration specified in milliseconds (default duration: 1000ms, default frame_rate: 11025).\n",
        "        chunk_silent = AudioSegment.silent(duration = 500, frame_rate=11025)\n",
        "  \n",
        "        # add 0.5 sec silence to beginning and \n",
        "        # end of audio chunk. This is done so that\n",
        "        # it doesn't seem abruptly sliced.\n",
        "        audio_chunk = chunk_silent + chunk + chunk_silent\n",
        "  \n",
        "        # export audio chunk and save it in \n",
        "        # the current directory.\n",
        "\n",
        "        # specify the bitrate to be 192 k\n",
        "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\")\n",
        "  \n",
        "        # the name of the newly created chunk\n",
        "        filename = 'chunk'+str(i)+'.wav'\n",
        "\n",
        "\n",
        "        # recognize the chunk\n",
        "     \n",
        "        audio = whisper.load_audio(filename)\n",
        "        audio = whisper.pad_or_trim(audio)\n",
        "        # make log-Mel spectrogram and move to the same device as the model\n",
        "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "        # decode the audio\n",
        "        options = whisper.DecodingOptions()\n",
        "        result = whisper.decode(model, mel, options)\n",
        "        #take only arabic and english\n",
        "        result=re.sub('[^\\u0600-\\u06FF a-zA-Z0-9,?!.\\']',' ',result.text)\n",
        "        result = collapse_whitespace(result)\n",
        "        TEXTS.append(result)\n",
        "        i+=1\n",
        "    os.chdir('..')\n",
        "    shutil.rmtree('audio_chunks', ignore_errors=True)\n",
        "    return TEXTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQAWle0oQcH5"
      },
      "source": [
        "# With silence_based_conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL4OOCMd2VFN",
        "outputId": "7a530991-7cc4-4652-fa94-a1229977d291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 49.8 s, sys: 8.73 s, total: 58.5 s\n",
            "Wall time: 1min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "TEXTS = mlt_speech_to_text_convertor(path = \"/content/en_ar_lecture.wav\",silence_based_conversion = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC_YYXOf6CrY",
        "outputId": "e5abe820-2547-4db0-a242-2d79570d4e4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Yeah',\n",
              " 'Uh',\n",
              " 'Uh',\n",
              " 'Oh',\n",
              " 'in',\n",
              " 'Uh',\n",
              " 'Uh',\n",
              " 'Bye!',\n",
              " 'Uh',\n",
              " 'Oh',\n",
              " 'Uh',\n",
              " 'I',\n",
              " 'Oh']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "TEXTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZGqEmIxQoOx"
      },
      "source": [
        "# Without silence_based_conversion (fixed length chunking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqnS4_UI9ilc",
        "outputId": "a2b18e81-3a73-4c98-a083-237ce3ce4627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 57.6 s, sys: 1.65 s, total: 59.2 s\n",
            "Wall time: 1min 2s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['بكت عيني بكت عيني بكت عيني على ذنبي وما لاقيت من كربي',\n",
              " 'and do not fear from the punishment.',\n",
              " 'will be the hafidh of the Quran the martyr the Shaheed and The one who gave of his money all the time for the sake of Allah these are the first three people whom Allah will call in front of him and As everybody is looking at them, they will think Allah is honoring them Allah is rewarding them Allah will give them the first share of the pie of Jannah',\n",
              " \"gatherings and at these masajid. Why did you go and do this? So the hafidh will stand up with pride and he will say, Oh Allah, I did it to bring honor to your book. I did it for the izzah of the religion, for the glory of the religion. I did it for your sake, Oh Allah. And Allah will say, You're lying. And the angels will agree and say, You are lying. And the books will be barred forth and it will be clear that his intention, Allah will say, your intention was not to please me.\",\n",
              " \"the Quran so that people would call you Qari, Hafiz, Sheikh and they did. So get your reward from them. And then the second person, the martyr, the one who waged a legitimate expedition and he gave his life for the cause of Allah subhanahu wa ta'ala. He will be asked why did you spend your life in the way of Allah and the man will say because I wanted to bring help to the religion. I wanted\",\n",
              " \"to defend the religion, defend the weakless and the homeless and the poor. I did it for your sake, O Allah. And Allah will once again say, كذبت, you're lying. And the angels will testify you're lying. And Allah will say, you only did it so that people could call you, mashaAllah, Mujahid, mashaAllah, brave man, mashaAllah, you've done so much. And the people did. You got your reward from them, none from Me. And the same with the third person,\",\n",
              " 'and for your religion. And Allah will say you only did it so that you could be known in the community. So that people would call you generous and that is exactly what they did. And then Allah will punish these three in front of all of the creation and they will be the very first people to enter the fire of hell. Wa liyadubillah. And Abu Huraira was listening to this hadith and the Prophet tapped his knee and he said, Ya Aba Huraira, these are the first three people',\n",
              " \"the Hafidh and Qari and in one rewired says the scholar and the orator may Allah azza wa jalla protect all of us and The one who was a Shaheed the martyr and the third one is the one who is generous why? Because their intentions were not correct. They had this mixing of intentions They wanted to show off their deeds and imagine brothers and sisters Imagine the fate of the person he's doing good his whole life and he thinks he's gonna meet Allah with all of this good\",\n",
              " \"and then he is told, you didn't do it for my sake. You did it for your own ego. You did it to inflate your own prestige on the people. Why are you wanting me to reward you when you didn't do it purely for my sake? Imagine the fate of that person and therefore brothers and sisters, we need to make sure we are not that person. We are not that person on the day of judgment who is told you wasted your whole life and all of your deeds will be thrown back at your face.\",\n",
              " 'اخلي ويا خجلي اذا ما قال لي ربي اما استحييته تعصيني ولا تخشى من العتبي وتخفي الذنب عن خلقي وتأبى في الهوى قربي',\n",
              " 'تعود إلى رضا ربي']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "TEXTS = mlt_speech_to_text_convertor(path = \"/content/en_ar_lecture.wav\",silence_based_conversion = False)\n",
        "\n",
        "TEXTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEja9kfiRS0s"
      },
      "source": [
        "# STEP-2 : Multilingual text Translator (Translate only english and leave arabic as it is)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I3Z4-AGFIqxY"
      },
      "outputs": [],
      "source": [
        "def tag_arabic_text(text,ar_pattern=u'[\\u0600-\\u06FF]+',english_only = False):\n",
        "    # remove multiple spaces\n",
        "    data=re.sub(' +', ' ',text)\n",
        "    texts=[]\n",
        "    if \"।\" in data:punct=\"।\"\n",
        "    elif \".\" in data:punct=\".\"\n",
        "    else:punct=\"\\n\"\n",
        "    for text in data.split(punct):    \n",
        "        # create start and end\n",
        "        text=\"start\"+text+\"end\"\n",
        "        # tag text\n",
        "        parts=re.split(ar_pattern, text)\n",
        "        parts=[p for p in parts if p.strip()]\n",
        "        parts=set(parts)\n",
        "        for m in parts:\n",
        "            if len(m.strip())>1:text=text.replace(m,f\"</ar>{m}<ar>\")\n",
        "        # clean-up invalid combos\n",
        "        text=text.replace(\"</ar>start\",'')\n",
        "        text=text.replace(\"end<ar>\",'')\n",
        "        texts.append(text)\n",
        "    text=f\"{punct}\".join(texts)\n",
        "    if(english_only):\n",
        "        #https://stackoverflow.com/questions/55656429/replace-or-remove-html-tag-content-python-regex\n",
        "        return re.sub(r'(?s)<ar>.*?</ar>', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "YALB07WVSglj",
        "outputId": "5736f037-c4ad-4de8-d57b-7b37ffb702ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<ar>بكت عيني بكت عيني بكت عيني على ذنبي وما لاقيت من كربي</ar> and do not fear from the punishment. will be the hafidh of the Quran the martyr the Shaheed and The one who gave of his money all the time for the sake of Allah these are the first three people whom Allah will call in front of him and As everybody is looking at them, they will think Allah is honoring them Allah is rewarding them Allah will give them the first share of the pie of Jannah gatherings and at these masajid. Why did you go and do this? So the hafidh will stand up with pride and he will say, Oh Allah, I did it to bring honor to your book. I did it for the izzah of the religion, for the glory of the religion. I did it for your sake, Oh Allah. And Allah will say, You're lying. And the angels will agree and say, You are lying. And the books will be barred forth and it will be clear that his intention, Allah will say, your intention was not to please me. the Quran so that people would call you Qari, Hafiz, Sheikh and they did. So get your reward from them. And then the second person, the martyr, the one who waged a legitimate expedition and he gave his life for the cause of Allah subhanahu wa ta'ala. He will be asked why did you spend your life in the way of Allah and the man will say because I wanted to bring help to the religion. I wanted to defend the religion, defend the weakless and the homeless and the poor. I did it for your sake, O Allah. And Allah will once again say, <ar>كذبت</ar>, you're lying. And the angels will testify you're lying. And Allah will say, you only did it so that people could call you, mashaAllah, Mujahid, mashaAllah, brave man, mashaAllah, you've done so much. And the people did. You got your reward from them, none from Me. And the same with the third person, and for your religion. And Allah will say you only did it so that you could be known in the community. So that people would call you generous and that is exactly what they did. And then Allah will punish these three in front of all of the creation and they will be the very first people to enter the fire of hell. Wa liyadubillah. And Abu Huraira was listening to this hadith and the Prophet tapped his knee and he said, Ya Aba Huraira, these are the first three people the Hafidh and Qari and in one rewired says the scholar and the orator may Allah azza wa jalla protect all of us and The one who was a Shaheed the martyr and the third one is the one who is generous why? Because their intentions were not correct. They had this mixing of intentions They wanted to show off their deeds and imagine brothers and sisters Imagine the fate of the person he's doing good his whole life and he thinks he's gonna meet Allah with all of this good and then he is told, you didn't do it for my sake. You did it for your own ego. You did it to inflate your own prestige on the people. Why are you wanting me to reward you when you didn't do it purely for my sake? Imagine the fate of that person and therefore brothers and sisters, we need to make sure we are not that person. We are not that person on the day of judgment who is told you wasted your whole life and all of your deeds will be thrown back at your face. <ar>اخلي ويا خجلي اذا ما قال لي ربي اما استحييته تعصيني ولا تخشى من العتبي وتخفي الذنب عن خلقي وتأبى في الهوى قربي تعود إلى رضا ربي</ar>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "mlt_text = ' '.join(TEXTS)\n",
        "tag_texts = tag_arabic_text(mlt_text,ar_pattern=u'[\\u0600-\\u06FF]+',english_only = False)\n",
        "tag_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "dde0d8d1a91045f38269043e381d978d",
            "6fcf285b937d49518bd8029f7281cefb",
            "cc591dbb59084d18918e7813faddcf75",
            "eb136d8de79644769a9d7f28ceba2428",
            "a8c62f1f011d4f9ead05e6885b1099a9",
            "6234d222b45a4e6d83ae8af0a7a94293",
            "d4355ef7060d460992ff1bbc88f9cbce",
            "dd291633b32f40479cc56c47b2fccb83",
            "ef1c7472f0af42a882c592a1d544f187",
            "fd0c581abb3e44eb9603aa61247b9241",
            "b56cdae458c946c2a1e747a43af8e78d",
            "0cebd4096dd645c5ae642ee337b54855",
            "22d9b543eb7c4cec9449f11015a690ec",
            "d3f8857ff27d432da47b79b746be1863",
            "7fa28f769f314a41b89b79016b558232",
            "ed04b6f9ce404d66b685ff73f42df739",
            "6bb529214d784a0e896a43c31f4398db",
            "3c7f6504ad684014bdbcd6d4516a9c38",
            "2d37008d94ec4504ad2022b4cc07b23b",
            "64a0aca260fe42ffb8d86b57154fc06a",
            "bf15c97108824b23a7cf8c3d76867e66",
            "ed0ede9b861c432c90fd6fbc559427db",
            "3d4f5868aad3410b9cc8b57089ce2286",
            "8b78ef53f7bd4165b0c74d696c33c53a",
            "262a39d60cf3453d940d83da733375fa",
            "5f7da38285fa4262b4c3cdd9a4d18c0c",
            "f059a0a8b0d04eed9b91ef9f1aedcfce",
            "584bf7f77e72442ebaa76bfbfd7b3e97",
            "bc3121c6562b4575a7f4f9c7795050c2",
            "67286d89a0d14b5f89cfe07f24197e5c",
            "a523de9bd1154f01a554d8942e0323e9",
            "085fa56539a5461dbc7632c0dde10add",
            "4301bb448d334de4b8944cf32fc0ceff",
            "c7218802398f41b883d622c557fc1eac",
            "aeb7832cd10b4633864406ad3676dd28",
            "df5f9e9074004758870b050349e5e13a",
            "3bbcb28c617b4d9b90088e44ab76ecb5",
            "72bfd0bc7e2e4c3284a2de729c8637fa",
            "8f0ac50c58b74e9986a6a09ee21f42f1",
            "4a948957624d4b878ec79e033d7f2d75",
            "1b4fafb3c4ee45939524f8f0723ce6f4",
            "42bd65f4547d43d692a34af2797bfb6b",
            "850d4d69fa544f21b28ef4ed631399d8",
            "8b73aad76da64bb8890a879a911b0365",
            "5ab14f0249e34fe18a9b4724fcc362f4",
            "652623c8f09f46cbb666b712c810c92d",
            "9c39064be62b4495a987f944683763ea",
            "92f56f0399a948bc98e6686a0a8f20d9",
            "20f88ad66b174e64b99b4b8a7f732ded",
            "8ba672779fb04fe1acd7cbb06b67d08a",
            "3eed4a8a3dab4c3bbddf065ab3639cc2",
            "a6a3fec90c164e04993dba84a8cd61cb",
            "61ae83bc209a4e6ebabb7bde856fcbe3",
            "a8d52c71b6954903b8ac0b2f4071252c",
            "4a4a77fcc0d54dd68d68e6ffbd33a391"
          ]
        },
        "id": "8q6JBRbFSq_I",
        "outputId": "64890e51-df94-40ce-c386-556eff566750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/766 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dde0d8d1a91045f38269043e381d978d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cebd4096dd645c5ae642ee337b54855"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d4f5868aad3410b9cc8b57089ce2286"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7218802398f41b883d622c557fc1eac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ab14f0249e34fe18a9b4724fcc362f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1364: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 128 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " সবকিছুর জন্য আলহামদুলিল্লাহ।\n"
          ]
        }
      ],
      "source": [
        "\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(torch_device)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/banglat5_nmt_en_bn\").to(torch_device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5_nmt_en_bn\",use_fast=True)\n",
        "\n",
        "def translate_en_bn(input_sentence):\n",
        "    # thanks to banglanmt : https://huggingface.co/csebuetnlp/banglat5_nmt_en_bn/discussions\n",
        "    input_ids = tokenizer(normalize(input_sentence), return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to(torch_device)\n",
        "    generated_tokens = model.generate(input_ids)\n",
        "    decoded_tokens = tokenizer.batch_decode(generated_tokens)[0]\n",
        "    decoded_tokens=decoded_tokens.replace(\"<pad>\",\"\").replace(\"</s>\",\"\")\n",
        "    # sen=decoded_tokens.split()\n",
        "    # words=[w for w in sen if w.strip()]\n",
        "    # sen=\" \".join(words)\n",
        "    return decoded_tokens\n",
        "\n",
        "def EN_AR_to_BN_AR_Translator(en_text,tag_text = False):\n",
        "    '''\n",
        "    translates multilingual english-arabic code mixed text into \n",
        "    multilingual bengali-arabic code mixed text\n",
        "    ''' \n",
        "    if(tag_text):\n",
        "        en_text = tag_arabic_text(en_text,english_only=False)\n",
        "    \n",
        "    sentenceEnders = re.compile('[.,!?]')\n",
        "    sentences = sentenceEnders.split(en_text)\n",
        "    main_list = []\n",
        "    for i in range(len(sentences)):\n",
        "        \n",
        "        list_str = sentences[i].split('<ar>')\n",
        "        if(len(list_str) == 1):\n",
        "            main_list.append(list_str[0])\n",
        "        else:\n",
        "            for j in range(len(list_str)):\n",
        "                if('</ar>' in list_str[j]):\n",
        "                    list_str1 = list_str[j].split('</ar>')\n",
        "                    main_list.append(\"<ar>\"+list_str1[0]+\"</ar>\")\n",
        "                    main_list.append(list_str1[1])\n",
        "                else:\n",
        "                    main_list.append(list_str[j])\n",
        "\n",
        "    while(\" \" in main_list):\n",
        "        main_list.remove(\" \")\n",
        "    for idx in range(len(main_list)):\n",
        "        if('<ar>' not in main_list[idx] or '</ar>' not in main_list[idx]):\n",
        "            \n",
        "            output_sentence = []\n",
        "            for word in main_list[idx].split():\n",
        "                output_sentence.append(word)\n",
        "     \n",
        "            main_list[idx] = ' '.join(output_sentence)\n",
        "            #numerizer\n",
        "            main_list[idx] = bangla.convert_english_digit_to_bangla_digit(main_list[idx])\n",
        "            # multilingual english-arabic to multilingual bengali-arabic\n",
        "            try:\n",
        "                if len(main_list[idx])>1:\n",
        "                    main_list[idx]=translate_en_bn(main_list[idx])\n",
        "                            \n",
        "            except:\n",
        "                print(\"failed -> \",main_list[idx])\n",
        "    \n",
        "    bn_mlt = \" \".join(main_list)\n",
        "    bn_mlt = re.sub(' ্ ','',bn_mlt)\n",
        "    bn_mlt = re.sub(\"\\\\'\",\"\",bn_mlt)#replace \\'\n",
        "    bn_mlt = re.sub('<unk>','',bn_mlt)\n",
        "    return bn_mlt\n",
        "        \n",
        "text=translate_en_bn(\"alhamdulillah for everything.\")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "hVeQ2QUsSt2S",
        "outputId": "ebe3b47f-624e-427a-b7fa-3ce132c84b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.9 s, sys: 60.7 ms, total: 14 s\n",
            "Wall time: 13.9 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' <ar>بكت عيني بكت عيني بكت عيني على ذنبي وما لاقيت من كربي</ar>  এবং শাস্তি থেকে ভীত হবেন না  কুরআনের হাফেজ হবে শহীদ শহীদ এবং যে তার অর্থ সর্বদা আল্লাহর উদ্দেশ্যে দান করেছে তারাই প্রথম তিন জন যাদেরকে আল্লাহ তাঁর সামনে ডেকে নেবেন এবং সবাই তাদের দিকে তাকিয়ে থাকবে।  তারা মনে করবে আল্লাহ তাদের সম্মানিত করছেন আল্লাহ তাদের পুরস্কৃত করছেন আল্লাহ তাদেরকে জান্নাতের প্রথম অংশ দেবেন এবং এই মসজিদগুলোতে  তুমি কেন গিয়ে এটা করলে?  তাই হাফিজ গর্বের সাথে দাঁড়াবে এবং বলবে  হে আল্লাহ  আমি এটা করেছি আপনার বইয়ের সম্মান আনতে  আমি এটা ধর্মের ইজ্জার জন্য করেছি  ধর্মের গৌরবার্থে  আমি এটা তোমার জন্য করেছি  হে আল্লাহ  এবং আল্লাহ বলবেন  তুমি মিথ্যা বলছ  আর ফেরেশতারা রাজি হয়ে বলবে  তুমি মিথ্যা বলছ  এবং বই নিষিদ্ধ করা হবে এবং এটা স্পষ্ট হবে যে তার উদ্দেশ্য  আল্লাহ বলবেন  তোমার উদ্দেশ্য আমাকে খুশি করা ছিল না  কুরআন যাতে মানুষ আপনাকে কারি বলে ডাকে  হাফিজ  শেখ এবং তারা করেছিল  তাই তাদের কাছ থেকে পুরস্কার নিন  এবং তারপর দ্বিতীয় ব্যক্তি  শহীদ  যিনি একটি বৈধ অভিযান পরিচালনা করেন এবং আল্লাহ সুবহানাহু ওয়া তাআলার উদ্দেশ্যে নিজের জীবন দান করেন।  তাকে জিজ্ঞাসা করা হবে কেন আপনি আপনার জীবন আল্লাহর পথে ব্যয় করেছেন এবং লোকটি বলবে কারণ আমি ধর্মের সাহায্য আনতে চেয়েছিলাম  আমি ধর্মকে রক্ষা করতে চেয়েছিলাম  দুর্বল ও গৃহহীন ও দরিদ্রদের রক্ষা করা  আমি এটা তোমার জন্য করেছি  হে আল্লাহ  আর আল্লাহ আরো একবার বলবেন <ar>كذبت</ar>   তুমি মিথ্যা বলছ  আর ফেরেশতারা সাক্ষ্য দেবে যে তুমি মিথ্যা বলছ  এবং আল্লাহ বলবেন  আপনি শুধু এটা করেছেন যাতে মানুষ আপনাকে ডাকতে পারে  মাশাআল্লাহ  মুজাহিদ  মাশাআল্লাহ  বীরপুরুষ  মাশাআল্লাহ  তুমি অনেক কিছু করেছ  আর লোকেরা তা-ই করেছিল  তুমি তাদের কাছ থেকে পুরস্কার পেয়েছ  আমার থেকে কেউ না  এবং তৃতীয় ব্যক্তির ক্ষেত্রেও একই কথা প্রযোজ্য  এবং আপনার ধর্মের জন্য  আর আল্লাহ বলবেন যে তুমি এটা করেছ যাতে তুমি সমাজে পরিচিত হতে পারো  তাই মানুষ আপনাকে উদার বলবে এবং ঠিক তাই তারা করেছিল  এবং তারপর আল্লাহ এই তিনজনকে সমস্ত সৃষ্টির সামনে শাস্তি দেবেন এবং তারাই হবে প্রথম মানুষ যারা জাহান্নামের আগুনে প্রবেশ করবে  ওয়া লিয়াদুবিল্লাহ  আবু হুরাইরা এই হাদীসটি শুনছিলেন এবং রাসূলুল্লাহ্ (স.) হাঁটু গেড়ে বললেন,  ইয়া আবা হুরাইরা  এদের মধ্যে প্রথম তিন জন হাফিজ ও কারি এবং একজন পুনর্নবীকরণে বলেছেন যে পণ্ডিত ও বক্তা আল্লাহ আজজা ওয়া জাল্লা আমাদের সকলকে রক্ষা করুন এবং যিনি শহীদ শহীদ এবং তৃতীয়জন যিনি উদার তিনি কেন এত উদার  কারণ তাদের উদ্দেশ্য সঠিক ছিল না  তাদের এই মিশ্র উদ্দেশ্য ছিল তারা তাদের কাজ প্রদর্শন করতে চেয়েছিলেন এবং কল্পনা করুন ভাই ও বোনেরা কল্পনা করুন যে ব্যক্তি তার সারা জীবন ভাল কাজ করছেন তার ভাগ্য কল্পনা করুন এবং তিনি মনে করেন যে তিনি এই সমস্ত ভাল কাজের সাথে আল্লাহর সাথে দেখা করবেন এবং তারপর তাকে বলা হয়  তুমি এটা আমার জন্য করনি  তুমি এটা তোমার নিজের জন্য করেছ  তুমি এটা করেছ মানুষের উপর তোমার নিজের সম্মান বাড়ানোর জন্য  কেন তুমি চাও আমি তোমাকে পুরস্কৃত করি যখন তুমি এটা আমার জন্য করো নি  সেই ব্যক্তি ও সেইসঙ্গে তার ভাই-বোনদের পরিণতি সম্বন্ধে কল্পনা করুন  আমাদের নিশ্চিত হতে হবে যে আমরা সেই ব্যক্তি নই  বিচারের দিনে আমরা সেই ব্যক্তি নই যাকে বলা হবে যে তুমি তোমার সারা জীবন নষ্ট করেছ এবং তোমার সমস্ত কাজ তোমার মুখে ফিরিয়ে দেওয়া হবে <ar>اخلي ويا خجلي اذا ما قال لي ربي اما استحييته تعصيني ولا تخشى من العتبي وتخفي الذنب عن خلقي وتأبى في الهوى قربي تعود إلى رضا ربي</ar> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "bn_mlt = EN_AR_to_BN_AR_Translator(tag_texts,tag_text = False)\n",
        "bn_mlt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9b_6RgOUtZb",
        "outputId": "030c0d27-7e8f-4a0d-b956-749224904c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  بكت عيني بكت عيني بكت عيني على ذنبي وما لاقيت من كربي   এবং শাস্তি থেকে ভীত হবেন না  কুরআনের হাফেজ হবে শহীদ শহীদ এবং যে তার অর্থ সর্বদা আল্লাহর উদ্দেশ্যে দান করেছে তারাই প্রথম তিন জন যাদেরকে আল্লাহ তাঁর সামনে ডেকে নেবেন এবং সবাই তাদের দিকে তাকিয়ে থাকবে।  তারা মনে করবে আল্লাহ তাদের সম্মানিত করছেন আল্লাহ তাদের পুরস্কৃত করছেন আল্লাহ তাদেরকে জান্নাতের প্রথম অংশ দেবেন এবং এই মসজিদগুলোতে  তুমি কেন গিয়ে এটা করলে?  তাই হাফিজ গর্বের সাথে দাঁড়াবে এবং বলবে  হে আল্লাহ  আমি এটা করেছি আপনার বইয়ের সম্মান আনতে  আমি এটা ধর্মের ইজ্জার জন্য করেছি  ধর্মের গৌরবার্থে  আমি এটা তোমার জন্য করেছি  হে আল্লাহ  এবং আল্লাহ বলবেন  তুমি মিথ্যা বলছ  আর ফেরেশতারা রাজি হয়ে বলবে  তুমি মিথ্যা বলছ  এবং বই নিষিদ্ধ করা হবে এবং এটা স্পষ্ট হবে যে তার উদ্দেশ্য  আল্লাহ বলবেন  তোমার উদ্দেশ্য আমাকে খুশি করা ছিল না  কুরআন যাতে মানুষ আপনাকে কারি বলে ডাকে  হাফিজ  শেখ এবং তারা করেছিল  তাই তাদের কাছ থেকে পুরস্কার নিন  এবং তারপর দ্বিতীয় ব্যক্তি  শহীদ  যিনি একটি বৈধ অভিযান পরিচালনা করেন এবং আল্লাহ সুবহানাহু ওয়া তাআলার উদ্দেশ্যে নিজের জীবন দান করেন।  তাকে জিজ্ঞাসা করা হবে কেন আপনি আপনার জীবন আল্লাহর পথে ব্যয় করেছেন এবং লোকটি বলবে কারণ আমি ধর্মের সাহায্য আনতে চেয়েছিলাম  আমি ধর্মকে রক্ষা করতে চেয়েছিলাম  দুর্বল ও গৃহহীন ও দরিদ্রদের রক্ষা করা  আমি এটা তোমার জন্য করেছি  হে আল্লাহ  আর আল্লাহ আরো একবার বলবেন  كذبت    তুমি মিথ্যা বলছ  আর ফেরেশতারা সাক্ষ্য দেবে যে তুমি মিথ্যা বলছ  এবং আল্লাহ বলবেন  আপনি শুধু এটা করেছেন যাতে মানুষ আপনাকে ডাকতে পারে  মাশাআল্লাহ  মুজাহিদ  মাশাআল্লাহ  বীরপুরুষ  মাশাআল্লাহ  তুমি অনেক কিছু করেছ  আর লোকেরা তা-ই করেছিল  তুমি তাদের কাছ থেকে পুরস্কার পেয়েছ  আমার থেকে কেউ না  এবং তৃতীয় ব্যক্তির ক্ষেত্রেও একই কথা প্রযোজ্য  এবং আপনার ধর্মের জন্য  আর আল্লাহ বলবেন যে তুমি এটা করেছ যাতে তুমি সমাজে পরিচিত হতে পারো  তাই মানুষ আপনাকে উদার বলবে এবং ঠিক তাই তারা করেছিল  এবং তারপর আল্লাহ এই তিনজনকে সমস্ত সৃষ্টির সামনে শাস্তি দেবেন এবং তারাই হবে প্রথম মানুষ যারা জাহান্নামের আগুনে প্রবেশ করবে  ওয়া লিয়াদুবিল্লাহ  আবু হুরাইরা এই হাদীসটি শুনছিলেন এবং রাসূলুল্লাহ্ (স.) হাঁটু গেড়ে বললেন,  ইয়া আবা হুরাইরা  এদের মধ্যে প্রথম তিন জন হাফিজ ও কারি এবং একজন পুনর্নবীকরণে বলেছেন যে পণ্ডিত ও বক্তা আল্লাহ আজজা ওয়া জাল্লা আমাদের সকলকে রক্ষা করুন এবং যিনি শহীদ শহীদ এবং তৃতীয়জন যিনি উদার তিনি কেন এত উদার  কারণ তাদের উদ্দেশ্য সঠিক ছিল না  তাদের এই মিশ্র উদ্দেশ্য ছিল তারা তাদের কাজ প্রদর্শন করতে চেয়েছিলেন এবং কল্পনা করুন ভাই ও বোনেরা কল্পনা করুন যে ব্যক্তি তার সারা জীবন ভাল কাজ করছেন তার ভাগ্য কল্পনা করুন এবং তিনি মনে করেন যে তিনি এই সমস্ত ভাল কাজের সাথে আল্লাহর সাথে দেখা করবেন এবং তারপর তাকে বলা হয়  তুমি এটা আমার জন্য করনি  তুমি এটা তোমার নিজের জন্য করেছ  তুমি এটা করেছ মানুষের উপর তোমার নিজের সম্মান বাড়ানোর জন্য  কেন তুমি চাও আমি তোমাকে পুরস্কৃত করি যখন তুমি এটা আমার জন্য করো নি  সেই ব্যক্তি ও সেইসঙ্গে তার ভাই-বোনদের পরিণতি সম্বন্ধে কল্পনা করুন  আমাদের নিশ্চিত হতে হবে যে আমরা সেই ব্যক্তি নই  বিচারের দিনে আমরা সেই ব্যক্তি নই যাকে বলা হবে যে তুমি তোমার সারা জীবন নষ্ট করেছ এবং তোমার সমস্ত কাজ তোমার মুখে ফিরিয়ে দেওয়া হবে  اخلي ويا خجلي اذا ما قال لي ربي اما استحييته تعصيني ولا تخشى من العتبي وتخفي الذنب عن خلقي وتأبى في الهوى قربي تعود إلى رضا ربي  \n"
          ]
        }
      ],
      "source": [
        "bn_mlt=bn_mlt.replace(\"</ar>\",' ')\n",
        "bn_mlt=bn_mlt.replace(\"<ar>\",' ')\n",
        "print(bn_mlt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFa4yVo-hNM5"
      },
      "source": [
        "Step 3 : Multilingual Text to Speech Pipeline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAOMFNPPhbZW"
      },
      "source": [
        "# Arabic tacotron2 TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di-LJsyrb55L",
        "outputId": "a23ad415-59d5-4298-f5bb-67906a203cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tts-arabic-tacotron2'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 58 (delta 3), reused 58 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nipponjo/tts-arabic-tacotron2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bkgW4Quwb9bS"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/tts-arabic-tacotron2')\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from model.networks import Tacotron2Wave\n",
        "from IPython.display import Audio\n",
        "import soundfile as sf\n",
        "import shutil\n",
        "import bangla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peNBpr1ChduC",
        "outputId": "84244350-93c5-40fa-d243-5a9533b52d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1CMvxg7zP1xoJbCLaJTbBCf1YU1SHl4uT tacotron2_ar.pth\n",
            "Retrieving folder 1uHomQ-7dxwTc8DagzSjIIdCHiSEncROE UNIVERSAL_V1\n",
            "Processing file 1_uRBHf9VmK6CGoB9c0Jb6nE8Gah7X6WI config.json\n",
            "Processing file 1ejejcJ2l9AL0AnP79Ag-XK3HZzBYW64h do_02500000\n",
            "Processing file 1oUGwFAAsRnM3OfwSWJVFJKyBmBZHc4fp g_02500000\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CMvxg7zP1xoJbCLaJTbBCf1YU1SHl4uT\n",
            "To: /content/arabic_tts/tacotron2_ar.pth\n",
            "100%|██████████| 338M/338M [00:03<00:00, 105MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_uRBHf9VmK6CGoB9c0Jb6nE8Gah7X6WI\n",
            "To: /content/arabic_tts/UNIVERSAL_V1/config.json\n",
            "100%|██████████| 799/799 [00:00<00:00, 1.65MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ejejcJ2l9AL0AnP79Ag-XK3HZzBYW64h\n",
            "To: /content/arabic_tts/UNIVERSAL_V1/do_02500000\n",
            "100%|██████████| 960M/960M [00:11<00:00, 83.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oUGwFAAsRnM3OfwSWJVFJKyBmBZHc4fp\n",
            "To: /content/arabic_tts/UNIVERSAL_V1/g_02500000\n",
            "100%|██████████| 55.8M/55.8M [00:01<00:00, 46.4MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/arabic_tts/tacotron2_ar.pth',\n",
              " '/content/arabic_tts/UNIVERSAL_V1/config.json',\n",
              " '/content/arabic_tts/UNIVERSAL_V1/do_02500000',\n",
              " '/content/arabic_tts/UNIVERSAL_V1/g_02500000']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "url = \"https://drive.google.com/drive/folders/196xZbqqxzsBQdKr1UKdh_wL_9qtJkt6u?usp=sharing\"\n",
        "gdown.download_folder(url=url, quiet=False, use_cookies=False)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o2_gwuvThgig"
      },
      "outputs": [],
      "source": [
        "shutil.copy('/content/arabic_tts/UNIVERSAL_V1/config.json', './tts-arabic-tacotron2/pretrained/hifigan-universal-v1')\n",
        "\n",
        "shutil.copy('/content/arabic_tts/UNIVERSAL_V1/do_02500000', './tts-arabic-tacotron2/pretrained/hifigan-universal-v1')\n",
        "\n",
        "shutil.copy('/content/arabic_tts/UNIVERSAL_V1/g_02500000', './tts-arabic-tacotron2/pretrained/hifigan-universal-v1')\n",
        "\n",
        "shutil.copy('/content/arabic_tts/tacotron2_ar.pth', './tts-arabic-tacotron2/pretrained')\n",
        "\n",
        "model_sd_path = './tts-arabic-tacotron2/pretrained/tacotron2_ar.pth'\n",
        "# vocoder\n",
        "vocoder_state_path = './tts-arabic-tacotron2/pretrained/hifigan-universal-v1/g_02500000'\n",
        "\n",
        "vocoder_config_path = './tts-arabic-tacotron2/pretrained/hifigan-universal-v1/config.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIdGdCszhidg",
        "outputId": "f7888eb1-66f6-4662-cff9-ff4bea22dc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/tts-arabic-tacotron2/utils/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/tts-arabic-tacotron2/utils/__init__.py\n",
        "import sys\n",
        "import yaml\n",
        "try:\n",
        "    from yaml import CLoader as Loader\n",
        "except ImportError:\n",
        "    from yaml import Loader\n",
        "\n",
        "\n",
        "class DictConfig(object):\n",
        "    \"\"\"Creates a Config object from a dict \n",
        "       such that object attributes correspond to dict keys.    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config_dict):\n",
        "        self.__dict__.update(config_dict)\n",
        "\n",
        "    def __str__(self):\n",
        "        return '\\n'.join(f\"{key}: {val}\" for key, val in self.__dict__.items())\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "def get_custom_config(fname):\n",
        "    with open(fname, 'r') as stream:\n",
        "        config_dict = yaml.load(stream, Loader)\n",
        "    config = DictConfig(config_dict)\n",
        "    return config\n",
        "\n",
        "\n",
        "def get_basic_config():\n",
        "    return get_custom_config('./tts-arabic-tacotron2/configs/basic.yaml')\n",
        "\n",
        "\n",
        "def get_config(fname):\n",
        "    config = get_basic_config()\n",
        "    custom_config = get_custom_config(fname)\n",
        "\n",
        "    config.__dict__.update(custom_config.__dict__)\n",
        "    return config\n",
        "\n",
        "\n",
        "def read_lines_from_file(path, encoding='utf-8'):\n",
        "    lines = []\n",
        "    with open(path, 'r', encoding=encoding) as f:\n",
        "        for line in f:\n",
        "            lines.append(line.strip())\n",
        "    return lines\n",
        "\n",
        "\n",
        "def progbar(iterable, length=30, symbol='='):\n",
        "    \"\"\"Wrapper generator function for an iterable. \n",
        "       Prints a progressbar when yielding an item. \\\\\n",
        "       Args:\n",
        "          iterable: an object supporting iteration\n",
        "          length: length of the progressbar\n",
        "    \"\"\"\n",
        "    n = len(iterable)\n",
        "    for i, item in enumerate(iterable):\n",
        "        steps = length*(i+1) // n\n",
        "        sys.stdout.write('\\r')\n",
        "        sys.stdout.write(f\"[{symbol*steps:{length}}] {(100/n*(i+1)):.1f}%\")\n",
        "        if i == (n-1):\n",
        "            sys.stdout.write('\\n')\n",
        "        sys.stdout.flush()\n",
        "        yield item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7Gb33KKNhkuG"
      },
      "outputs": [],
      "source": [
        "ar_model = Tacotron2Wave(model_sd_path = model_sd_path,vocoder_sd = vocoder_state_path, vocoder_config = vocoder_config_path)\n",
        "#ar_model = ar_model.cuda()\n",
        "ar_model = ar_model.to(torch_device) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xoCT2NVhpbm"
      },
      "source": [
        "# Bangla TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PADpeqbghnFu",
        "outputId": "38238955-a2ba-42b7-9103-856d967e015a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coundn't import TTS synthesizer,trying again!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "try:\n",
        "  from TTS.utils.synthesizer import Synthesizer\n",
        "except:\n",
        "  print(\"coundn't import TTS synthesizer,trying again!\")\n",
        "#from TTS.utils.synthesizer import Synthesizer\n",
        "\n",
        "import TTS\n",
        "\n",
        "TTS.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qROi3dxrhtvn"
      },
      "source": [
        "Removing annoying print statement during inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mcqdlIsMhrVG"
      },
      "outputs": [],
      "source": [
        "# from https://github.com/coqui-ai/TTS/blob/dev/TTS/utils/synthesizer.py\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pysbd\n",
        "import torch\n",
        "\n",
        "from TTS.config import load_config\n",
        "from TTS.tts.models import setup_model as setup_tts_model\n",
        "\n",
        "# pylint: disable=unused-wildcard-import\n",
        "# pylint: disable=wildcard-import\n",
        "from TTS.tts.utils.synthesis import synthesis, transfer_voice, trim_silence\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.vocoder.models import setup_model as setup_vocoder_model\n",
        "from TTS.vocoder.utils.generic_utils import interpolate_vocoder_input\n",
        "\n",
        "\n",
        "class Synthesizer(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tts_checkpoint: str,\n",
        "        tts_config_path: str,\n",
        "        tts_speakers_file: str = \"\",\n",
        "        tts_languages_file: str = \"\",\n",
        "        vocoder_checkpoint: str = \"\",\n",
        "        vocoder_config: str = \"\",\n",
        "        encoder_checkpoint: str = \"\",\n",
        "        encoder_config: str = \"\",\n",
        "        use_cuda: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"General 🐸 TTS interface for inference. It takes a tts and a vocoder\n",
        "        model and synthesize speech from the provided text.\n",
        "        The text is divided into a list of sentences using `pysbd` and synthesize\n",
        "        speech on each sentence separately.\n",
        "        If you have certain special characters in your text, you need to handle\n",
        "        them before providing the text to Synthesizer.\n",
        "        TODO: set the segmenter based on the source language\n",
        "        Args:\n",
        "            tts_checkpoint (str): path to the tts model file.\n",
        "            tts_config_path (str): path to the tts config file.\n",
        "            vocoder_checkpoint (str, optional): path to the vocoder model file. Defaults to None.\n",
        "            vocoder_config (str, optional): path to the vocoder config file. Defaults to None.\n",
        "            encoder_checkpoint (str, optional): path to the speaker encoder model file. Defaults to `\"\"`,\n",
        "            encoder_config (str, optional): path to the speaker encoder config file. Defaults to `\"\"`,\n",
        "            use_cuda (bool, optional): enable/disable cuda. Defaults to False.\n",
        "        \"\"\"\n",
        "        self.tts_checkpoint = tts_checkpoint\n",
        "        self.tts_config_path = tts_config_path\n",
        "        self.tts_speakers_file = tts_speakers_file\n",
        "        self.tts_languages_file = tts_languages_file\n",
        "        self.vocoder_checkpoint = vocoder_checkpoint\n",
        "        self.vocoder_config = vocoder_config\n",
        "        self.encoder_checkpoint = encoder_checkpoint\n",
        "        self.encoder_config = encoder_config\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        self.tts_model = None\n",
        "        self.vocoder_model = None\n",
        "        self.speaker_manager = None\n",
        "        self.num_speakers = 0\n",
        "        self.tts_speakers = {}\n",
        "        self.language_manager = None\n",
        "        self.num_languages = 0\n",
        "        self.tts_languages = {}\n",
        "        self.d_vector_dim = 0\n",
        "        self.seg = self._get_segmenter(\"en\")\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        if self.use_cuda:\n",
        "            assert torch.cuda.is_available(), \"CUDA is not availabe on this machine.\"\n",
        "        self._load_tts(tts_checkpoint, tts_config_path, use_cuda)\n",
        "        self.output_sample_rate = self.tts_config.audio[\"sample_rate\"]\n",
        "        if vocoder_checkpoint:\n",
        "            self._load_vocoder(vocoder_checkpoint, vocoder_config, use_cuda)\n",
        "            self.output_sample_rate = self.vocoder_config.audio[\"sample_rate\"]\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_segmenter(lang: str):\n",
        "        \"\"\"get the sentence segmenter for the given language.\n",
        "        Args:\n",
        "            lang (str): target language code.\n",
        "        Returns:\n",
        "            [type]: [description]\n",
        "        \"\"\"\n",
        "        return pysbd.Segmenter(language=lang, clean=True)\n",
        "\n",
        "    def _load_tts(self, tts_checkpoint: str, tts_config_path: str, use_cuda: bool) -> None:\n",
        "        \"\"\"Load the TTS model.\n",
        "        1. Load the model config.\n",
        "        2. Init the model from the config.\n",
        "        3. Load the model weights.\n",
        "        4. Move the model to the GPU if CUDA is enabled.\n",
        "        5. Init the speaker manager in the model.\n",
        "        Args:\n",
        "            tts_checkpoint (str): path to the model checkpoint.\n",
        "            tts_config_path (str): path to the model config file.\n",
        "            use_cuda (bool): enable/disable CUDA use.\n",
        "        \"\"\"\n",
        "        # pylint: disable=global-statement\n",
        "        self.tts_config = load_config(tts_config_path)\n",
        "        if self.tts_config[\"use_phonemes\"] and self.tts_config[\"phonemizer\"] is None:\n",
        "            raise ValueError(\"Phonemizer is not defined in the TTS config.\")\n",
        "\n",
        "        self.tts_model = setup_tts_model(config=self.tts_config)\n",
        "\n",
        "        if not self.encoder_checkpoint:\n",
        "            self._set_speaker_encoder_paths_from_tts_config()\n",
        "\n",
        "        self.tts_model.load_checkpoint(self.tts_config, tts_checkpoint, eval=True)\n",
        "        if use_cuda:\n",
        "            self.tts_model.cuda()\n",
        "\n",
        "        if self.encoder_checkpoint and hasattr(self.tts_model, \"speaker_manager\"):\n",
        "            self.tts_model.speaker_manager.init_encoder(self.encoder_checkpoint, self.encoder_config, use_cuda)\n",
        "\n",
        "    def _set_speaker_encoder_paths_from_tts_config(self):\n",
        "        \"\"\"Set the encoder paths from the tts model config for models with speaker encoders.\"\"\"\n",
        "        if hasattr(self.tts_config, \"model_args\") and hasattr(\n",
        "            self.tts_config.model_args, \"speaker_encoder_config_path\"\n",
        "        ):\n",
        "            self.encoder_checkpoint = self.tts_config.model_args.speaker_encoder_model_path\n",
        "            self.encoder_config = self.tts_config.model_args.speaker_encoder_config_path\n",
        "\n",
        "    def _load_vocoder(self, model_file: str, model_config: str, use_cuda: bool) -> None:\n",
        "        \"\"\"Load the vocoder model.\n",
        "        1. Load the vocoder config.\n",
        "        2. Init the AudioProcessor for the vocoder.\n",
        "        3. Init the vocoder model from the config.\n",
        "        4. Move the model to the GPU if CUDA is enabled.\n",
        "        Args:\n",
        "            model_file (str): path to the model checkpoint.\n",
        "            model_config (str): path to the model config file.\n",
        "            use_cuda (bool): enable/disable CUDA use.\n",
        "        \"\"\"\n",
        "        self.vocoder_config = load_config(model_config)\n",
        "        self.vocoder_ap = AudioProcessor(verbose=False, **self.vocoder_config.audio)\n",
        "        self.vocoder_model = setup_vocoder_model(self.vocoder_config)\n",
        "        self.vocoder_model.load_checkpoint(self.vocoder_config, model_file, eval=True)\n",
        "        if use_cuda:\n",
        "            self.vocoder_model.cuda()\n",
        "\n",
        "    def split_into_sentences(self, text) -> List[str]:\n",
        "        \"\"\"Split give text into sentences.\n",
        "        Args:\n",
        "            text (str): input text in string format.\n",
        "        Returns:\n",
        "            List[str]: list of sentences.\n",
        "        \"\"\"\n",
        "        return self.seg.segment(text)\n",
        "\n",
        "    def save_wav(self, wav: List[int], path: str) -> None:\n",
        "        \"\"\"Save the waveform as a file.\n",
        "        Args:\n",
        "            wav (List[int]): waveform as a list of values.\n",
        "            path (str): output path to save the waveform.\n",
        "        \"\"\"\n",
        "        wav = np.array(wav)\n",
        "        self.tts_model.ap.save_wav(wav, path, self.output_sample_rate)\n",
        "\n",
        "    def tts(\n",
        "        self,\n",
        "        text: str = \"\",\n",
        "        speaker_name: str = \"\",\n",
        "        language_name: str = \"\",\n",
        "        speaker_wav=None,\n",
        "        style_wav=None,\n",
        "        style_text=None,\n",
        "        reference_wav=None,\n",
        "        reference_speaker_name=None,\n",
        "    ) -> List[int]:\n",
        "        \"\"\"🐸 TTS magic. Run all the models and generate speech.\n",
        "        Args:\n",
        "            text (str): input text.\n",
        "            speaker_name (str, optional): spekaer id for multi-speaker models. Defaults to \"\".\n",
        "            language_name (str, optional): language id for multi-language models. Defaults to \"\".\n",
        "            speaker_wav (Union[str, List[str]], optional): path to the speaker wav. Defaults to None.\n",
        "            style_wav ([type], optional): style waveform for GST. Defaults to None.\n",
        "            style_text ([type], optional): transcription of style_wav for Capacitron. Defaults to None.\n",
        "            reference_wav ([type], optional): reference waveform for voice conversion. Defaults to None.\n",
        "            reference_speaker_name ([type], optional): spekaer id of reference waveform. Defaults to None.\n",
        "        Returns:\n",
        "            List[int]: [description]\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        wavs = []\n",
        "\n",
        "        if not text and not reference_wav:\n",
        "            raise ValueError(\n",
        "                \"You need to define either `text` (for sythesis) or a `reference_wav` (for voice conversion) to use the Coqui TTS API.\"\n",
        "            )\n",
        "\n",
        "        if text:\n",
        "            sens = self.split_into_sentences(text)\n",
        "            # print(\" > Text splitted to sentences.\")\n",
        "            # print(sens)\n",
        "\n",
        "        # handle multi-speaker\n",
        "        speaker_embedding = None\n",
        "        speaker_id = None\n",
        "        if self.tts_speakers_file or hasattr(self.tts_model.speaker_manager, \"name_to_id\"):\n",
        "            if speaker_name and isinstance(speaker_name, str):\n",
        "                if self.tts_config.use_d_vector_file:\n",
        "                    # get the average speaker embedding from the saved d_vectors.\n",
        "                    speaker_embedding = self.tts_model.speaker_manager.get_mean_embedding(\n",
        "                        speaker_name, num_samples=None, randomize=False\n",
        "                    )\n",
        "                    speaker_embedding = np.array(speaker_embedding)[None, :]  # [1 x embedding_dim]\n",
        "                else:\n",
        "                    # get speaker idx from the speaker name\n",
        "                    speaker_id = self.tts_model.speaker_manager.name_to_id[speaker_name]\n",
        "\n",
        "            elif not speaker_name and not speaker_wav:\n",
        "                raise ValueError(\n",
        "                    \" [!] Look like you use a multi-speaker model. \"\n",
        "                    \"You need to define either a `speaker_name` or a `speaker_wav` to use a multi-speaker model.\"\n",
        "                )\n",
        "            else:\n",
        "                speaker_embedding = None\n",
        "        else:\n",
        "            if speaker_name:\n",
        "                raise ValueError(\n",
        "                    f\" [!] Missing speakers.json file path for selecting speaker {speaker_name}.\"\n",
        "                    \"Define path for speaker.json if it is a multi-speaker model or remove defined speaker idx. \"\n",
        "                )\n",
        "\n",
        "        # handle multi-lingaul\n",
        "        language_id = None\n",
        "        if self.tts_languages_file or (\n",
        "            hasattr(self.tts_model, \"language_manager\") and self.tts_model.language_manager is not None\n",
        "        ):\n",
        "            if language_name and isinstance(language_name, str):\n",
        "                language_id = self.tts_model.language_manager.name_to_id[language_name]\n",
        "\n",
        "            elif not language_name:\n",
        "                raise ValueError(\n",
        "                    \" [!] Look like you use a multi-lingual model. \"\n",
        "                    \"You need to define either a `language_name` or a `style_wav` to use a multi-lingual model.\"\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\" [!] Missing language_ids.json file path for selecting language {language_name}.\"\n",
        "                    \"Define path for language_ids.json if it is a multi-lingual model or remove defined language idx. \"\n",
        "                )\n",
        "\n",
        "        # compute a new d_vector from the given clip.\n",
        "        if speaker_wav is not None:\n",
        "            speaker_embedding = self.tts_model.speaker_manager.compute_embedding_from_clip(speaker_wav)\n",
        "\n",
        "        use_gl = self.vocoder_model is None\n",
        "\n",
        "        if not reference_wav:\n",
        "            for sen in sens:\n",
        "                # synthesize voice\n",
        "                outputs = synthesis(\n",
        "                    model=self.tts_model,\n",
        "                    text=sen,\n",
        "                    CONFIG=self.tts_config,\n",
        "                    use_cuda=self.use_cuda,\n",
        "                    speaker_id=speaker_id,\n",
        "                    style_wav=style_wav,\n",
        "                    style_text=style_text,\n",
        "                    use_griffin_lim=use_gl,\n",
        "                    d_vector=speaker_embedding,\n",
        "                    language_id=language_id,\n",
        "                )\n",
        "                waveform = outputs[\"wav\"]\n",
        "                mel_postnet_spec = outputs[\"outputs\"][\"model_outputs\"][0].detach().cpu().numpy()\n",
        "                if not use_gl:\n",
        "                    # denormalize tts output based on tts audio config\n",
        "                    mel_postnet_spec = self.tts_model.ap.denormalize(mel_postnet_spec.T).T\n",
        "                    device_type = \"cuda\" if self.use_cuda else \"cpu\"\n",
        "                    # renormalize spectrogram based on vocoder config\n",
        "                    vocoder_input = self.vocoder_ap.normalize(mel_postnet_spec.T)\n",
        "                    # compute scale factor for possible sample rate mismatch\n",
        "                    scale_factor = [\n",
        "                        1,\n",
        "                        self.vocoder_config[\"audio\"][\"sample_rate\"] / self.tts_model.ap.sample_rate,\n",
        "                    ]\n",
        "                    if scale_factor[1] != 1:\n",
        "                        print(\" > interpolating tts model output.\")\n",
        "                        vocoder_input = interpolate_vocoder_input(scale_factor, vocoder_input)\n",
        "                    else:\n",
        "                        vocoder_input = torch.tensor(vocoder_input).unsqueeze(0)  # pylint: disable=not-callable\n",
        "                    # run vocoder model\n",
        "                    # [1, T, C]\n",
        "                    waveform = self.vocoder_model.inference(vocoder_input.to(device_type))\n",
        "                if self.use_cuda and not use_gl:\n",
        "                    waveform = waveform.cpu()\n",
        "                if not use_gl:\n",
        "                    waveform = waveform.numpy()\n",
        "                waveform = waveform.squeeze()\n",
        "\n",
        "                # trim silence\n",
        "                if \"do_trim_silence\" in self.tts_config.audio and self.tts_config.audio[\"do_trim_silence\"]:\n",
        "                    waveform = trim_silence(waveform, self.tts_model.ap)\n",
        "\n",
        "                wavs += list(waveform)\n",
        "                wavs += [0] * 10000\n",
        "        else:\n",
        "            # get the speaker embedding or speaker id for the reference wav file\n",
        "            reference_speaker_embedding = None\n",
        "            reference_speaker_id = None\n",
        "            if self.tts_speakers_file or hasattr(self.tts_model.speaker_manager, \"name_to_id\"):\n",
        "                if reference_speaker_name and isinstance(reference_speaker_name, str):\n",
        "                    if self.tts_config.use_d_vector_file:\n",
        "                        # get the speaker embedding from the saved d_vectors.\n",
        "                        reference_speaker_embedding = self.tts_model.speaker_manager.get_embeddings_by_name(\n",
        "                            reference_speaker_name\n",
        "                        )[0]\n",
        "                        reference_speaker_embedding = np.array(reference_speaker_embedding)[\n",
        "                            None, :\n",
        "                        ]  # [1 x embedding_dim]\n",
        "                    else:\n",
        "                        # get speaker idx from the speaker name\n",
        "                        reference_speaker_id = self.tts_model.speaker_manager.name_to_id[reference_speaker_name]\n",
        "                else:\n",
        "                    reference_speaker_embedding = self.tts_model.speaker_manager.compute_embedding_from_clip(\n",
        "                        reference_wav\n",
        "                    )\n",
        "            outputs = transfer_voice(\n",
        "                model=self.tts_model,\n",
        "                CONFIG=self.tts_config,\n",
        "                use_cuda=self.use_cuda,\n",
        "                reference_wav=reference_wav,\n",
        "                speaker_id=speaker_id,\n",
        "                d_vector=speaker_embedding,\n",
        "                use_griffin_lim=use_gl,\n",
        "                reference_speaker_id=reference_speaker_id,\n",
        "                reference_d_vector=reference_speaker_embedding,\n",
        "            )\n",
        "            waveform = outputs\n",
        "            if not use_gl:\n",
        "                mel_postnet_spec = outputs[0].detach().cpu().numpy()\n",
        "                # denormalize tts output based on tts audio config\n",
        "                mel_postnet_spec = self.tts_model.ap.denormalize(mel_postnet_spec.T).T\n",
        "                device_type = \"cuda\" if self.use_cuda else \"cpu\"\n",
        "                # renormalize spectrogram based on vocoder config\n",
        "                vocoder_input = self.vocoder_ap.normalize(mel_postnet_spec.T)\n",
        "                # compute scale factor for possible sample rate mismatch\n",
        "                scale_factor = [\n",
        "                    1,\n",
        "                    self.vocoder_config[\"audio\"][\"sample_rate\"] / self.tts_model.ap.sample_rate,\n",
        "                ]\n",
        "                if scale_factor[1] != 1:\n",
        "                    print(\" > interpolating tts model output.\")\n",
        "                    vocoder_input = interpolate_vocoder_input(scale_factor, vocoder_input)\n",
        "                else:\n",
        "                    vocoder_input = torch.tensor(vocoder_input).unsqueeze(0)  # pylint: disable=not-callable\n",
        "                # run vocoder model\n",
        "                # [1, T, C]\n",
        "                waveform = self.vocoder_model.inference(vocoder_input.to(device_type))\n",
        "            if self.use_cuda:\n",
        "                waveform = waveform.cpu()\n",
        "            if not use_gl:\n",
        "                waveform = waveform.numpy()\n",
        "            wavs = waveform.squeeze()\n",
        "\n",
        "        # compute stats\n",
        "        process_time = time.time() - start_time\n",
        "        audio_time = len(wavs) / self.tts_config.audio[\"sample_rate\"]\n",
        "        # print(f\" > Processing time: {process_time}\")\n",
        "        # print(f\" > Real-time factor: {process_time / audio_time}\")\n",
        "        return wavs\n",
        "\n",
        "\n",
        "\n",
        "# from https://github.com/coqui-ai/TTS/blob/dev/TTS/tts/utils/text/tokenizer.py\n",
        "\n",
        "from typing import Callable, Dict, List, Union\n",
        "\n",
        "from TTS.tts.utils.text import cleaners\n",
        "from TTS.tts.utils.text.characters import Graphemes, IPAPhonemes\n",
        "from TTS.tts.utils.text.phonemizers import DEF_LANG_TO_PHONEMIZER, get_phonemizer_by_name\n",
        "from TTS.utils.generic_utils import get_import_path, import_class\n",
        "\n",
        "\n",
        "class TTSTokenizer:\n",
        "    \"\"\"🐸TTS tokenizer to convert input characters to token IDs and back.\n",
        "    Token IDs for OOV chars are discarded but those are stored in `self.not_found_characters` for later.\n",
        "    Args:\n",
        "        use_phonemes (bool):\n",
        "            Whether to use phonemes instead of characters. Defaults to False.\n",
        "        characters (Characters):\n",
        "            A Characters object to use for character-to-ID and ID-to-character mappings.\n",
        "        text_cleaner (callable):\n",
        "            A function to pre-process the text before tokenization and phonemization. Defaults to None.\n",
        "        phonemizer (Phonemizer):\n",
        "            A phonemizer object or a dict that maps language codes to phonemizer objects. Defaults to None.\n",
        "    Example:\n",
        "        >>> from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "        >>> tokenizer = TTSTokenizer(use_phonemes=False, characters=Graphemes())\n",
        "        >>> text = \"Hello world!\"\n",
        "        >>> ids = tokenizer.text_to_ids(text)\n",
        "        >>> text_hat = tokenizer.ids_to_text(ids)\n",
        "        >>> assert text == text_hat\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        use_phonemes=False,\n",
        "        text_cleaner: Callable = None,\n",
        "        characters: \"BaseCharacters\" = None,\n",
        "        phonemizer: Union[\"Phonemizer\", Dict] = None,\n",
        "        add_blank: bool = False,\n",
        "        use_eos_bos=False,\n",
        "    ):\n",
        "        self.text_cleaner = text_cleaner\n",
        "        self.use_phonemes = use_phonemes\n",
        "        self.add_blank = add_blank\n",
        "        self.use_eos_bos = use_eos_bos\n",
        "        self.characters = characters\n",
        "        self.not_found_characters = []\n",
        "        self.phonemizer = phonemizer\n",
        "\n",
        "    @property\n",
        "    def characters(self):\n",
        "        return self._characters\n",
        "\n",
        "    @characters.setter\n",
        "    def characters(self, new_characters):\n",
        "        self._characters = new_characters\n",
        "        self.pad_id = self.characters.char_to_id(self.characters.pad) if self.characters.pad else None\n",
        "        self.blank_id = self.characters.char_to_id(self.characters.blank) if self.characters.blank else None\n",
        "\n",
        "    def encode(self, text: str) -> List[int]:\n",
        "        \"\"\"Encodes a string of text as a sequence of IDs.\"\"\"\n",
        "        token_ids = []\n",
        "        for char in text:\n",
        "            try:\n",
        "                idx = self.characters.char_to_id(char)\n",
        "                token_ids.append(idx)\n",
        "            except KeyError:\n",
        "                # discard but store not found characters\n",
        "                if char not in self.not_found_characters:\n",
        "                    self.not_found_characters.append(char)\n",
        "                    # print(text)\n",
        "                    # print(f\" [!] Character {repr(char)} not found in the vocabulary. Discarding it.\")\n",
        "        return token_ids\n",
        "\n",
        "    def decode(self, token_ids: List[int]) -> str:\n",
        "        \"\"\"Decodes a sequence of IDs to a string of text.\"\"\"\n",
        "        text = \"\"\n",
        "        for token_id in token_ids:\n",
        "            text += self.characters.id_to_char(token_id)\n",
        "        return text\n",
        "\n",
        "    def text_to_ids(self, text: str, language: str = None) -> List[int]:  # pylint: disable=unused-argument\n",
        "        \"\"\"Converts a string of text to a sequence of token IDs.\n",
        "        Args:\n",
        "            text(str):\n",
        "                The text to convert to token IDs.\n",
        "            language(str):\n",
        "                The language code of the text. Defaults to None.\n",
        "        TODO:\n",
        "            - Add support for language-specific processing.\n",
        "        1. Text normalizatin\n",
        "        2. Phonemization (if use_phonemes is True)\n",
        "        3. Add blank char between characters\n",
        "        4. Add BOS and EOS characters\n",
        "        5. Text to token IDs\n",
        "        \"\"\"\n",
        "        # TODO: text cleaner should pick the right routine based on the language\n",
        "        if self.text_cleaner is not None:\n",
        "            text = self.text_cleaner(text)\n",
        "        if self.use_phonemes:\n",
        "            text = self.phonemizer.phonemize(text, separator=\"\")\n",
        "        if self.add_blank:\n",
        "            text = self.intersperse_blank_char(text, True)\n",
        "        if self.use_eos_bos:\n",
        "            text = self.pad_with_bos_eos(text)\n",
        "        return self.encode(text)\n",
        "\n",
        "    def ids_to_text(self, id_sequence: List[int]) -> str:\n",
        "        \"\"\"Converts a sequence of token IDs to a string of text.\"\"\"\n",
        "        return self.decode(id_sequence)\n",
        "\n",
        "    def pad_with_bos_eos(self, char_sequence: List[str]):\n",
        "        \"\"\"Pads a sequence with the special BOS and EOS characters.\"\"\"\n",
        "        return [self.characters.bos] + list(char_sequence) + [self.characters.eos]\n",
        "\n",
        "    def intersperse_blank_char(self, char_sequence: List[str], use_blank_char: bool = False):\n",
        "        \"\"\"Intersperses the blank character between characters in a sequence.\n",
        "        Use the ```blank``` character if defined else use the ```pad``` character.\n",
        "        \"\"\"\n",
        "        char_to_use = self.characters.blank if use_blank_char else self.characters.pad\n",
        "        result = [char_to_use] * (len(char_sequence) * 2 + 1)\n",
        "        result[1::2] = char_sequence\n",
        "        return result\n",
        "\n",
        "    def print_logs(self, level: int = 0):\n",
        "        indent = \"\\t\" * level\n",
        "        print(f\"{indent}| > add_blank: {self.add_blank}\")\n",
        "        print(f\"{indent}| > use_eos_bos: {self.use_eos_bos}\")\n",
        "        print(f\"{indent}| > use_phonemes: {self.use_phonemes}\")\n",
        "        if self.use_phonemes:\n",
        "            print(f\"{indent}| > phonemizer:\")\n",
        "            self.phonemizer.print_logs(level + 1)\n",
        "        if len(self.not_found_characters) > 0:\n",
        "            print(f\"{indent}| > {len(self.not_found_characters)} not found characters:\")\n",
        "            for char in self.not_found_characters:\n",
        "                print(f\"{indent}| > {char}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def init_from_config(config: \"Coqpit\", characters: \"BaseCharacters\" = None):\n",
        "        \"\"\"Init Tokenizer object from config\n",
        "        Args:\n",
        "            config (Coqpit): Coqpit model config.\n",
        "            characters (BaseCharacters): Defines the model character set. If not set, use the default options based on\n",
        "                the config values. Defaults to None.\n",
        "        \"\"\"\n",
        "        # init cleaners\n",
        "        text_cleaner = None\n",
        "        if isinstance(config.text_cleaner, (str, list)):\n",
        "            text_cleaner = getattr(cleaners, config.text_cleaner)\n",
        "\n",
        "        # init characters\n",
        "        if characters is None:\n",
        "            # set characters based on defined characters class\n",
        "            if config.characters and config.characters.characters_class:\n",
        "                CharactersClass = import_class(config.characters.characters_class)\n",
        "                characters, new_config = CharactersClass.init_from_config(config)\n",
        "            # set characters based on config\n",
        "            else:\n",
        "                if config.use_phonemes:\n",
        "                    # init phoneme set\n",
        "                    characters, new_config = IPAPhonemes().init_from_config(config)\n",
        "                else:\n",
        "                    # init character set\n",
        "                    characters, new_config = Graphemes().init_from_config(config)\n",
        "\n",
        "        else:\n",
        "            characters, new_config = characters.init_from_config(config)\n",
        "\n",
        "        # set characters class\n",
        "        new_config.characters.characters_class = get_import_path(characters)\n",
        "\n",
        "        # init phonemizer\n",
        "        phonemizer = None\n",
        "        if config.use_phonemes:\n",
        "            phonemizer_kwargs = {\"language\": config.phoneme_language}\n",
        "\n",
        "            if \"phonemizer\" in config and config.phonemizer:\n",
        "                phonemizer = get_phonemizer_by_name(config.phonemizer, **phonemizer_kwargs)\n",
        "            else:\n",
        "                try:\n",
        "                    phonemizer = get_phonemizer_by_name(\n",
        "                        DEF_LANG_TO_PHONEMIZER[config.phoneme_language], **phonemizer_kwargs\n",
        "                    )\n",
        "                    new_config.phonemizer = phonemizer.name()\n",
        "                except KeyError as e:\n",
        "                    raise ValueError(\n",
        "                        f\"\"\"No phonemizer found for language {config.phoneme_language}.\n",
        "                        You may need to install a third party library for this language.\"\"\"\n",
        "                    ) from e\n",
        "\n",
        "        return (\n",
        "            TTSTokenizer(\n",
        "                config.use_phonemes, text_cleaner, characters, phonemizer, config.add_blank, config.enable_eos_bos_chars\n",
        "            ),\n",
        "            new_config,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rufE0bIThzcy"
      },
      "source": [
        "# model selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6frCFnDdhwme",
        "outputId": "34533505-d34d-47ea-8dcc-50ad35ae481b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Using model: vits\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "# link -> hhttps://drive.google.com/drive/folders/1IMCiQpyYBqu98dlRMSINjFNc34fI6zhs?usp=sharing\n",
        "url = \"https://drive.google.com/drive/folders/1IMCiQpyYBqu98dlRMSINjFNc34fI6zhs?usp=sharing\"\n",
        "gdown.download_folder(url=url, quiet=True, use_cookies=False)   \n",
        "\n",
        "male = True\n",
        "if(male):\n",
        "  # test_ckpt = '/content/bangla_tts/bn_glow_tts/male/checkpoint_328000.pth'\n",
        "  # test_config = '/content/bangla_tts/bn_glow_tts/male/config.json'\n",
        "\n",
        "  test_ckpt = '/content/bangla_tts/bn_vits/male/best_model_2360.pth'\n",
        "  test_config = '/content/bangla_tts/bn_vits/male/config.json'\n",
        "\n",
        "else:\n",
        "  test_ckpt = '/content/bangla_tts/bn_glow_tts/female/checkpoint_180000.pth'\n",
        "  test_config = '/content/bangla_tts/bn_glow_tts/female/config.json'\n",
        "\n",
        "bn_model=Synthesizer(test_ckpt,test_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0YYYQw5h4Kg"
      },
      "source": [
        "# Mlt large text to audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IiwwWpe2h1ho"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torchaudio.functional as F\n",
        "import torchaudio\n",
        "from bnnumerizer import numerize\n",
        "import gc\n",
        "from bnunicodenormalizer import Normalizer \n",
        "from pydub import AudioSegment\n",
        "from pyarabic.araby import strip_diacritics\n",
        "\n",
        "# initialize\n",
        "bnorm=Normalizer()\n",
        "\n",
        "# Create empty audio file of half second duration (purpose -> post processing)\n",
        "\n",
        "audio = AudioSegment.silent(duration=500)\n",
        "sound = audio.set_frame_rate(audio.frame_rate*2)\n",
        "sound.export(\"./empty.wav\", format=\"wav\")\n",
        "\n",
        "#loading empty audio file of  1 second to append before and after each arabic chunk for increasing mlt reading rhythm.\n",
        "\n",
        "empty_audio, rate_of_sample = torchaudio.load('/content/empty.wav')\n",
        "empty_audio = empty_audio.flatten()\n",
        "\n",
        "def normalize(sen):\n",
        "    _words = [bnorm(word)['normalized']  for word in sen.split()]\n",
        "    return \" \".join([word for word in _words if word is not None]) \n",
        "\n",
        "class BigTextToAudio(object):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 ar_model,\n",
        "                 bn_model,\n",
        "                 ar_sample_rate=22050,\n",
        "                 bn_sample_rate=22050,\n",
        "                 out_sample_rate=22050,\n",
        "        \n",
        "                 attribution_dict={\"সাঃ\":\"সাল্লাল্লাহু আলাইহি ওয়া সাল্লাম\",    \n",
        "                                   \"স.\":\"সাল্লাল্লাহু আলাইহি ওয়া সাল্লাম\",                \n",
        "                                  \"আঃ\":\"আলাইহিস সালাম\",\n",
        "                                  \"রাঃ\":\"রাদিআল্লাহু আনহু\",\n",
        "                                  \"রহঃ\":\"রহমাতুল্লাহি আলাইহি\",\n",
        "                                  \"রহিঃ\":\"রহিমাহুল্লাহ\",\n",
        "                                  \"হাফিঃ\":\"হাফিযাহুল্লাহ\",\n",
        "                                  # \"বায়ান\":\"বাইআন\",\n",
        "                                  \"দাঃবাঃ\":\"দামাত বারাকাতুহুম,দামাত বারাকাতুল্লাহ\",\n",
        "                                  #\"আয়াত\" : \"আইআত\",#আইআত\n",
        "                                  # \"ওয়া\" : \"ওআ\",\n",
        "                                  # \"ওয়াসাল্লাম\"  : \"ওআসাল্লাম\",\n",
        "                                  # \"কেন\"  : \"কেনো\",\n",
        "                                  # \"কোন\" : \"কোনো\",\n",
        "                                  # \"বল\"   : \"বলো\",\n",
        "                                  # \"চল\"   : \"চলো\",\n",
        "                                  # \"কর\"   : \"করো\",\n",
        "                                  # \"রাখ\"   : \"রাখো\",\n",
        "                                  \"’\"     :  \"\",\n",
        "                                  \"‘\"     : \"\",\n",
        "                                  # \"য়\"     : \"অ\",\n",
        "                                  # \"সম্প্রদায়\" : \"সম্প্রদাই\",\n",
        "                                  # \"রয়েছে\"   : \"রইছে\",\n",
        "                                  # \"রয়েছ\"    : \"রইছ\",\n",
        "                                   \"/\"   : \" বাই \",\n",
        "                                  },\n",
        "                resample_params={\"lowpass_filter_width\": 64,\n",
        "                                \"rolloff\": 0.9475937167399596,\n",
        "                                \"resampling_method\": \"kaiser_window\",\n",
        "                                \"beta\": 14.769656459379492}\n",
        "                ):\n",
        "        '''\n",
        "            Instantiates a Big Text to Audio conversion object for bangla and arabic\n",
        "            args:\n",
        "                ar_model : arabic tts model\n",
        "                bn_model : bangla tts model\n",
        "                ar_sample_rate : arabic audio sample rate [optional] default: 22050\n",
        "                bn_sample_rate : bangla audio sample rate [optional] default: 22050\n",
        "                out_sample_rate : audio sample rate [optional] default: 22050\n",
        "                attribution_dict : a dict for attribution expansion [optional]\n",
        "                resample_params : audio resampling parameters [optional]\n",
        "            resources:\n",
        "                # Main class: modified from https://github.com/snakers4/silero-models/pull/174\n",
        "                # Audio converter:https://www.kaggle.com/code/shahruk10/inference-notebook-wav2vec2\n",
        "        '''\n",
        "        self.ar_model = ar_model\n",
        "        self.bn_model = bn_model\n",
        "\n",
        "        self.attribution_dict=attribution_dict\n",
        "\n",
        "        self.ar_sample_rate=ar_sample_rate\n",
        "        self.bn_sample_rate=bn_sample_rate\n",
        "        self.sample_rate=out_sample_rate  \n",
        "        self.resample_params=resample_params\n",
        "        \n",
        "    # public\n",
        "    def ar_tts(self,text):\n",
        "        '''\n",
        "            args: \n",
        "                text: arabic text (string)\n",
        "            returns:\n",
        "                audio as torch tensor\n",
        "        '''\n",
        "        text = strip_diacritics(text)\n",
        "        try:\n",
        "          audio = self.ar_model.tts(text)\n",
        "          audio = torch.cat([empty_audio,audio], axis=0) #start empty\n",
        "          audio = torch.cat([audio,empty_audio], axis=0) #end empty\n",
        "          audio = audio \n",
        "        except:\n",
        "            print(\"failed ar =>\",text,\"end\")\n",
        "            audio = empty_audio \n",
        "                  \n",
        "        \n",
        "        return audio\n",
        "    # public\n",
        "    def bn_tts(self,text):\n",
        "        '''\n",
        "            args: \n",
        "                text   : bangla text (string)\n",
        "            returns:\n",
        "                audio as torch tensor\n",
        "        '''\n",
        "\n",
        "\n",
        "        return torch.as_tensor(self.bn_model.tts(text))\n",
        "    \n",
        "    # public\n",
        "    def expand_full_attribution(self,text):\n",
        "        for word in self.attribution_dict:\n",
        "            if word in text:\n",
        "                text = text.replace(word, normalize(self.attribution_dict[word]))\n",
        "        return text\n",
        "    \n",
        "\n",
        "    def collapse_whitespace(self,text):\n",
        "        # Regular expression matching whitespace:\n",
        "        _whitespace_re = re.compile(r\"\\s+\")\n",
        "        return re.sub(_whitespace_re, \" \", text)\n",
        "\n",
        "    # public\n",
        "    def tag_text(self,text):\n",
        "        '''\n",
        "            * tags arabic text with <ar>text</ar>\n",
        "            * tags bangla text with <bn>text</bn>\n",
        "        '''\n",
        "        # remove multiple spaces\n",
        "        text=re.sub(' +', ' ',text)\n",
        "        # create start and end\n",
        "        text=\"start\"+text+\"end\"\n",
        "        # tag text\n",
        "        parts=re.split(u'[\\u0600-\\u06FF]+', text)\n",
        "        # remove non chars\n",
        "        parts=[p for p in parts if p.strip()]\n",
        "        # unique parts\n",
        "        parts=set(parts)\n",
        "        # tag the text\n",
        "        for m in parts:\n",
        "            if len(m.strip())>1:text=text.replace(m,f\"</ar><SPLIT><bn>{m}</bn><SPLIT><ar>\")\n",
        "        # clean-tags\n",
        "        text=text.replace(\"</ar><SPLIT><bn>start\",'<bn>')\n",
        "        text=text.replace(\"end</bn><SPLIT><ar>\",'</bn>')\n",
        "        return text\n",
        "\n",
        "    def process_text(self,text):\n",
        "        '''\n",
        "        process multilingual text for suitable MLT TTS format\n",
        "            * expand attributions\n",
        "            * numerize text\n",
        "            * tag sections of the text\n",
        "            * sequentially list text blocks\n",
        "            * Split based on sentence ending Characters\n",
        "\n",
        "        '''\n",
        "        \n",
        "        # english numbers to bangla conversion\n",
        "        res = re.search('[0-9]', text)\n",
        "        if res is not None:\n",
        "          text = bangla.convert_english_digit_to_bangla_digit(text)\n",
        "        \n",
        "        #replace ':' in between two bangla numbers with ' এর '\n",
        "        pattern=r\"[০, ১, ২, ৩, ৪, ৫, ৬, ৭, ৮, ৯]:[০, ১, ২, ৩, ৪, ৫, ৬, ৭, ৮, ৯]\"\n",
        "        matches=re.findall(pattern,text)\n",
        "        for m in matches:\n",
        "            r=m.replace(\":\",\" এর \")\n",
        "            text=text.replace(m,r)\n",
        "\n",
        "        # numerize text\n",
        "        try:\n",
        "          text=numerize(text)\n",
        "        except:\n",
        "          print(\"couldn't numerize bengali.\")\n",
        "        # tag sections\n",
        "        # text=self.tag_text(text)\n",
        "\n",
        "        text=\"।\".join([self.tag_text(line) for line in text.split(\"।\")])\n",
        "\n",
        "        # text blocks\n",
        "        blocks=text.split(\"<SPLIT>\")\n",
        "        blocks=[b for b in blocks if b.strip()]\n",
        "        # create tuple of (lang,text)\n",
        "        data=[]\n",
        "        for block in blocks:\n",
        "            lang=None\n",
        "            if \"<bn>\" in block:\n",
        "                block=block.replace(\"<bn>\",'').replace(\"</bn>\",'')\n",
        "                lang=\"bn\"\n",
        "            elif \"<ar>\" in block:\n",
        "                block=block.replace(\"<ar>\",'').replace(\"</ar>\",'')\n",
        "                lang=\"ar\"\n",
        "            \n",
        "            # Split based on sentence ending Characters\n",
        "\n",
        "            if lang == \"bn\":\n",
        "              bn_text = block.strip()\n",
        "\n",
        "              sentenceEnders = re.compile('[।,!?]')\n",
        "              sentences = sentenceEnders.split(str(bn_text))\n",
        "\n",
        "              for i in range(len(sentences)):\n",
        "                  res = re.sub('\\n','',sentences[i])\n",
        "                  res = normalize(res)\n",
        "                  # expand attributes\n",
        "                  res=self.expand_full_attribution(res)\n",
        "\n",
        "                  res = self.collapse_whitespace(res)\n",
        "                  res += '।'\n",
        "                  data.append((lang,res))\n",
        "\n",
        "            elif lang == \"ar\":\n",
        "                ar_text = block.strip()\n",
        "                ar_text = re.sub(\"؟\", \"?\", ar_text) # replace any ؟ with ?\n",
        "\n",
        "                sentenceEnders = re.compile('[.,!?]')\n",
        "                sentences = sentenceEnders.split(str(ar_text))\n",
        "\n",
        "                for i in range(len(sentences)):\n",
        "                    res = re.sub('\\n','',sentences[i])\n",
        "                    res = self.collapse_whitespace(res)\n",
        "                    data.append((lang,res))\n",
        "                    \n",
        "        return data\n",
        "    \n",
        "    def resample_audio(self,audio,sr):\n",
        "        '''\n",
        "            resample audio with sample rate\n",
        "            args:\n",
        "                audio : torch.tensor audio\n",
        "                sr: audi sample rate\n",
        "        '''\n",
        "        if sr==self.sample_rate:\n",
        "            return audio\n",
        "        else:\n",
        "            return F.resample(audio,sr,self.sample_rate,**self.resample_params)\n",
        "        \n",
        "    \n",
        "    def get_audio(self,data):\n",
        "        '''\n",
        "            creates audio from given data \n",
        "                * data=List[Tuples(lang,text)]\n",
        "        '''\n",
        "        audio_list = []\n",
        "        for block in data:\n",
        "            lang,text=block\n",
        "            if lang==\"bn\":\n",
        "                audio=self.bn_tts(text)\n",
        "                sr=self.bn_sample_rate\n",
        "            else:\n",
        "                audio=self.ar_tts(text)\n",
        "                sr=self.ar_sample_rate\n",
        "            \n",
        "            if self.resample_audio_to_out_sample_rate:\n",
        "                audio=self.resample_audio(audio,sr)\n",
        "                \n",
        "            audio_list.append(audio)\n",
        "  \n",
        "        audio = torch.cat([k for k in audio_list])\n",
        "        return audio\n",
        "    \n",
        "    # call\n",
        "    def __call__(self,text,resample_audio_to_out_sample_rate=True):\n",
        "        '''\n",
        "            args: \n",
        "                text   : bangla text (string)\n",
        "                resample_audio_to_out_sample_rate: for different sample rate in different models, resample the output audio \n",
        "                                                   in uniform sample rate \n",
        "                                                   * default:True\n",
        "            returns:\n",
        "                audio as numpy data\n",
        "        '''\n",
        "        self.resample_audio_to_out_sample_rate=resample_audio_to_out_sample_rate\n",
        "        data=self.process_text(text)\n",
        "        audio=self.get_audio(data)\n",
        "        return audio.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWJvEF3eh-1X",
        "outputId": "655c9360-8707-4b9b-fbf8-e96e4fd39004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "couldn't numerize bengali.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bn', '।'),\n",
              " ('ar', 'بكت عيني بكت عيني بكت عيني على ذنبي وما لاقيت من كربي'),\n",
              " ('bn',\n",
              "  'এবং শাস্তি থেকে ভীত হবেন না কুরআনের হাফেজ হবে শহীদ শহীদ এবং যে তার অর্থ সর্বদা আল্লাহর উদ্দেশ্যে দান করেছে তারাই প্রথম তিন জন যাদেরকে আল্লাহ তাঁর সামনে ডেকে নেবেন এবং সবাই তাদের দিকে তাকিয়ে থাকবে।'),\n",
              " ('bn',\n",
              "  'তারা মনে করবে আল্লাহ তাদের সম্মানিত করছেন আল্লাহ তাদের পুরস্কৃত করছেন আল্লাহ তাদেরকে জান্নাতের প্রথম অংশ দেবেন এবং এই মসজিদগুলোতে তুমি কেন গিয়ে এটা করলে।'),\n",
              " ('bn',\n",
              "  'তাই হাফিজ গর্বের সাথে দাঁড়াবে এবং বলবে হে আল্লাহ আমি এটা করেছি আপনার বইয়ের সম্মান আনতে আমি এটা ধর্মের ইজ্জার জন্য করেছি ধর্মের গৌরবার্থে আমি এটা তোমার জন্য করেছি হে আল্লাহ এবং আল্লাহ বলবেন তুমি মিথ্যা বলছ আর ফেরেশতারা রাজি হয়ে বলবে তুমি মিথ্যা বলছ এবং বই নিষিদ্ধ করা হবে এবং এটা স্পষ্ট হবে যে তার উদ্দেশ্য আল্লাহ বলবেন তোমার উদ্দেশ্য আমাকে খুশি করা ছিল না কুরআন যাতে মানুষ আপনাকে কারি বলে ডাকে হাফিজ শেখ এবং তারা করেছিল তাই তাদের কাছ থেকে পুরস্কার নিন এবং তারপর দ্বিতীয় ব্যক্তি শহীদ যিনি একটি বৈধ অভিযান পরিচালনা করেন এবং আল্লাহ সুবহানাহু ওয়া তাআলার উদ্দেশ্যে নিজের জীবন দান করেন।'),\n",
              " ('bn',\n",
              "  'তাকে জিজ্ঞাসা করা হবে কেন আপনি আপনার জীবন আল্লাহর পথে ব্যয় করেছেন এবং লোকটি বলবে কারণ আমি ধর্মের সাহায্য আনতে চেয়েছিলাম আমি ধর্মকে রক্ষা করতে চেয়েছিলাম দুর্বল ও গৃহহীন ও দরিদ্রদের রক্ষা করা আমি এটা তোমার জন্য করেছি হে আল্লাহ আর আল্লাহ আরো একবার বলবেন।'),\n",
              " ('ar', 'كذبت'),\n",
              " ('bn',\n",
              "  'তুমি মিথ্যা বলছ আর ফেরেশতারা সাক্ষ্য দেবে যে তুমি মিথ্যা বলছ এবং আল্লাহ বলবেন আপনি শুধু এটা করেছেন যাতে মানুষ আপনাকে ডাকতে পারে মাশাআল্লাহ মুজাহিদ মাশাআল্লাহ বীরপুরুষ মাশাআল্লাহ তুমি অনেক কিছু করেছ আর লোকেরা তা-ই করেছিল তুমি তাদের কাছ থেকে পুরস্কার পেয়েছ আমার থেকে কেউ না এবং তৃতীয় ব্যক্তির ক্ষেত্রেও একই কথা প্রযোজ্য এবং আপনার ধর্মের জন্য আর আল্লাহ বলবেন যে তুমি এটা করেছ যাতে তুমি সমাজে পরিচিত হতে পারো তাই মানুষ আপনাকে উদার বলবে এবং ঠিক তাই তারা করেছিল এবং তারপর আল্লাহ এই তিনজনকে সমস্ত সৃষ্টির সামনে শাস্তি দেবেন এবং তারাই হবে প্রথম মানুষ যারা জাহান্নামের আগুনে প্রবেশ করবে ওয়া লিয়াদুবিল্লাহ আবু হুরাইরা এই হাদীসটি শুনছিলেন এবং রাসূলুল্লাহ (সাল্লাল্লাহু আলাইহি ওয়া সাল্লাম) হাঁটু গেড়ে বললেন।'),\n",
              " ('bn',\n",
              "  'ইয়া আবা হুরাইরা এদের মধ্যে প্রথম তিন জন হাফিজ ও কারি এবং একজন পুনর্নবীকরণে বলেছেন যে পণ্ডিত ও বক্তা আল্লাহ আজজা ওয়া জাল্লা আমাদের সকলকে রক্ষা করুন এবং যিনি শহীদ শহীদ এবং তৃতীয়জন যিনি উদার তিনি কেন এত উদার কারণ তাদের উদ্দেশ্য সঠিক ছিল না তাদের এই মিশ্র উদ্দেশ্য ছিল তারা তাদের কাজ প্রদর্শন করতে চেয়েছিলেন এবং কল্পনা করুন ভাই ও বোনেরা কল্পনা করুন যে ব্যক্তি তার সারা জীবন ভাল কাজ করছেন তার ভাগ্য কল্পনা করুন এবং তিনি মনে করেন যে তিনি এই সমস্ত ভাল কাজের সাথে আল্লাহর সাথে দেখা করবেন এবং তারপর তাকে বলা হয় তুমি এটা আমার জন্য করনি তুমি এটা তোমার নিজের জন্য করেছ তুমি এটা করেছ মানুষের উপর তোমার নিজের সম্মান বাড়ানোর জন্য কেন তুমি চাও আমি তোমাকে পুরস্কৃত করি যখন তুমি এটা আমার জন্য করো নি সেই ব্যক্তি ও সেইসঙ্গে তার ভাই-বোনদের পরিণতি সম্বন্ধে কল্পনা করুন আমাদের নিশ্চিত হতে হবে যে আমরা সেই ব্যক্তি নই বিচারের দিনে আমরা সেই ব্যক্তি নই যাকে বলা হবে যে তুমি তোমার সারা জীবন নষ্ট করেছ এবং তোমার সমস্ত কাজ তোমার মুখে ফিরিয়ে দেওয়া হবে।'),\n",
              " ('ar',\n",
              "  'اخلي ويا خجلي اذا ما قال لي ربي اما استحييته تعصيني ولا تخشى من العتبي وتخفي الذنب عن خلقي وتأبى في الهوى قربي تعود إلى رضا ربي'),\n",
              " ('bn', '।')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "mytext = bn_mlt\n",
        "\n",
        "MLT_TTS=BigTextToAudio(ar_model=ar_model,\n",
        "                   bn_model=bn_model)\n",
        "\n",
        "data=MLT_TTS.process_text(mytext)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_qv3A5Fnxdw"
      },
      "source": [
        "# Cross Lingual Text to Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uS6b8G0iDyX",
        "outputId": "0f9b84c2-7c12-4cfb-80c2-a09d31a2a430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "couldn't numerize bengali.\n",
            "['<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', 'থ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ফ', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'শ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', '্', '<BLNK>', 'ষ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', ' ', '<BLNK>', 'দ', '<BLNK>', 'ে', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', 'থ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'শ', '<BLNK>', 'ু', '<BLNK>', 'ধ', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ট', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ড', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'ু', '<BLNK>', 'জ', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', 'ি', '<BLNK>', 'দ', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ী', '<BLNK>', 'র', '<BLNK>', 'প', '<BLNK>', 'ু', '<BLNK>', 'র', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'অ', '<BLNK>', 'ন', '<BLNK>', 'ে', '<BLNK>', 'ক', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'ি', '<BLNK>', 'ছ', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ল', '<BLNK>', 'ো', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', '-', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'দ', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'া', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'থ', '<BLNK>', 'ে', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'ু', '<BLNK>', 'র', '<BLNK>', 'স', '<BLNK>', '্', '<BLNK>', 'ক', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'ে', '<BLNK>', 'য়', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'থ', '<BLNK>', 'ে', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', 'উ', '<BLNK>', ' ', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ৃ', '<BLNK>', 'ত', '<BLNK>', 'ী', '<BLNK>', 'য়', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', 'ক', '<BLNK>', '্', '<BLNK>', 'ত', '<BLNK>', 'ি', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', '্', '<BLNK>', 'ষ', '<BLNK>', 'ে', '<BLNK>', 'ত', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ও', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ক', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'থ', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'য', '<BLNK>', 'ো', '<BLNK>', 'জ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ধ', '<BLNK>', 'র', '<BLNK>', '্', '<BLNK>', 'ম', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'জ', '<BLNK>', 'ন', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ট', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'জ', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'র', '<BLNK>', 'ি', '<BLNK>', 'চ', '<BLNK>', 'ি', '<BLNK>', 'ত', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'ো', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'উ', '<BLNK>', 'দ', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ঠ', '<BLNK>', 'ি', '<BLNK>', 'ক', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'প', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ি', '<BLNK>', 'ন', '<BLNK>', 'জ', '<BLNK>', 'ন', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'ম', '<BLNK>', 'স', '<BLNK>', '্', '<BLNK>', 'ত', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'ৃ', '<BLNK>', 'ষ', '<BLNK>', '্', '<BLNK>', 'ট', '<BLNK>', 'ি', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ম', '<BLNK>', 'ন', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'স', '<BLNK>', '্', '<BLNK>', 'ত', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'দ', '<BLNK>', 'ে', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'থ', '<BLNK>', 'ম', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'জ', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', '্', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'ম', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'গ', '<BLNK>', 'ু', '<BLNK>', 'ন', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'শ', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ও', '<BLNK>', 'য়', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ল', '<BLNK>', 'ি', '<BLNK>', 'য়', '<BLNK>', 'া', '<BLNK>', 'দ', '<BLNK>', 'ু', '<BLNK>', 'ব', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ব', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'ু', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'া', '<BLNK>', 'দ', '<BLNK>', 'ী', '<BLNK>', 'স', '<BLNK>', 'ট', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'শ', '<BLNK>', 'ু', '<BLNK>', 'ন', '<BLNK>', 'ছ', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', 'স', '<BLNK>', 'ূ', '<BLNK>', 'ল', '<BLNK>', 'ু', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', '(', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', 'হ', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ও', '<BLNK>', 'য়', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'ম', '<BLNK>', ')', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'া', '<BLNK>', 'ঁ', '<BLNK>', 'ট', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'গ', '<BLNK>', 'ে', '<BLNK>', 'ড়', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ল', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', '।', '<BLNK>']\n",
            " [!] Character '(' not found in the vocabulary. Discarding it.\n",
            "['<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', 'থ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ফ', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'শ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', '্', '<BLNK>', 'ষ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', ' ', '<BLNK>', 'দ', '<BLNK>', 'ে', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', 'থ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'শ', '<BLNK>', 'ু', '<BLNK>', 'ধ', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ট', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ড', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'ু', '<BLNK>', 'জ', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', 'ি', '<BLNK>', 'দ', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ী', '<BLNK>', 'র', '<BLNK>', 'প', '<BLNK>', 'ু', '<BLNK>', 'র', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'অ', '<BLNK>', 'ন', '<BLNK>', 'ে', '<BLNK>', 'ক', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'ি', '<BLNK>', 'ছ', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ল', '<BLNK>', 'ো', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', '-', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'দ', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'া', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'থ', '<BLNK>', 'ে', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'ু', '<BLNK>', 'র', '<BLNK>', 'স', '<BLNK>', '্', '<BLNK>', 'ক', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'ে', '<BLNK>', 'য়', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'থ', '<BLNK>', 'ে', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', 'উ', '<BLNK>', ' ', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ৃ', '<BLNK>', 'ত', '<BLNK>', 'ী', '<BLNK>', 'য়', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', 'ক', '<BLNK>', '্', '<BLNK>', 'ত', '<BLNK>', 'ি', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', '্', '<BLNK>', 'ষ', '<BLNK>', 'ে', '<BLNK>', 'ত', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ও', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ক', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'থ', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'য', '<BLNK>', 'ো', '<BLNK>', 'জ', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ধ', '<BLNK>', 'র', '<BLNK>', '্', '<BLNK>', 'ম', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'জ', '<BLNK>', 'ন', '<BLNK>', '্', '<BLNK>', 'য', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ট', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ু', '<BLNK>', 'ম', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'জ', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'র', '<BLNK>', 'ি', '<BLNK>', 'চ', '<BLNK>', 'ি', '<BLNK>', 'ত', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'ত', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'ো', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'প', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'উ', '<BLNK>', 'দ', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ঠ', '<BLNK>', 'ি', '<BLNK>', 'ক', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ে', '<BLNK>', 'ছ', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'প', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'ি', '<BLNK>', 'ন', '<BLNK>', 'জ', '<BLNK>', 'ন', '<BLNK>', 'ক', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'ম', '<BLNK>', 'স', '<BLNK>', '্', '<BLNK>', 'ত', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'ৃ', '<BLNK>', 'ষ', '<BLNK>', '্', '<BLNK>', 'ট', '<BLNK>', 'ি', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ম', '<BLNK>', 'ন', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'শ', '<BLNK>', 'া', '<BLNK>', 'স', '<BLNK>', '্', '<BLNK>', 'ত', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'দ', '<BLNK>', 'ে', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'ত', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'থ', '<BLNK>', 'ম', '<BLNK>', ' ', '<BLNK>', 'ম', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', 'ু', '<BLNK>', 'ষ', '<BLNK>', ' ', '<BLNK>', 'য', '<BLNK>', 'া', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'জ', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', 'া', '<BLNK>', 'ন', '<BLNK>', '্', '<BLNK>', 'ন', '<BLNK>', 'া', '<BLNK>', 'ম', '<BLNK>', 'ে', '<BLNK>', 'র', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'গ', '<BLNK>', 'ু', '<BLNK>', 'ন', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'প', '<BLNK>', '্', '<BLNK>', 'র', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', 'শ', '<BLNK>', ' ', '<BLNK>', 'ক', '<BLNK>', 'র', '<BLNK>', 'ব', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ও', '<BLNK>', 'য়', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'ল', '<BLNK>', 'ি', '<BLNK>', 'য়', '<BLNK>', 'া', '<BLNK>', 'দ', '<BLNK>', 'ু', '<BLNK>', 'ব', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ব', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'ু', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ই', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'া', '<BLNK>', 'দ', '<BLNK>', 'ী', '<BLNK>', 'স', '<BLNK>', 'ট', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'শ', '<BLNK>', 'ু', '<BLNK>', 'ন', '<BLNK>', 'ছ', '<BLNK>', 'ি', '<BLNK>', 'ল', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', ' ', '<BLNK>', 'এ', '<BLNK>', 'ব', '<BLNK>', 'ং', '<BLNK>', ' ', '<BLNK>', 'র', '<BLNK>', 'া', '<BLNK>', 'স', '<BLNK>', 'ূ', '<BLNK>', 'ল', '<BLNK>', 'ু', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', ' ', '<BLNK>', '(', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'হ', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'আ', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'ই', '<BLNK>', 'হ', '<BLNK>', 'ি', '<BLNK>', ' ', '<BLNK>', 'ও', '<BLNK>', 'য়', '<BLNK>', 'া', '<BLNK>', ' ', '<BLNK>', 'স', '<BLNK>', 'া', '<BLNK>', 'ল', '<BLNK>', '্', '<BLNK>', 'ল', '<BLNK>', 'া', '<BLNK>', 'ম', '<BLNK>', ')', '<BLNK>', ' ', '<BLNK>', 'হ', '<BLNK>', 'া', '<BLNK>', 'ঁ', '<BLNK>', 'ট', '<BLNK>', 'ু', '<BLNK>', ' ', '<BLNK>', 'গ', '<BLNK>', 'ে', '<BLNK>', 'ড়', '<BLNK>', 'ে', '<BLNK>', ' ', '<BLNK>', 'ব', '<BLNK>', 'ল', '<BLNK>', 'ল', '<BLNK>', 'ে', '<BLNK>', 'ন', '<BLNK>', '।', '<BLNK>']\n",
            " [!] Character ')' not found in the vocabulary. Discarding it.\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "audio=MLT_TTS(mytext,resample_audio_to_out_sample_rate=False)\n",
        "sf.write('e2e_mlt_stt.wav', audio, 22050)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMoOQ9xbiP-X"
      },
      "outputs": [],
      "source": [
        "Audio(audio, rate=MLT_TTS.sample_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDcWwneePwWk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dde0d8d1a91045f38269043e381d978d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fcf285b937d49518bd8029f7281cefb",
              "IPY_MODEL_cc591dbb59084d18918e7813faddcf75",
              "IPY_MODEL_eb136d8de79644769a9d7f28ceba2428"
            ],
            "layout": "IPY_MODEL_a8c62f1f011d4f9ead05e6885b1099a9"
          }
        },
        "6fcf285b937d49518bd8029f7281cefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6234d222b45a4e6d83ae8af0a7a94293",
            "placeholder": "​",
            "style": "IPY_MODEL_d4355ef7060d460992ff1bbc88f9cbce",
            "value": "Downloading: 100%"
          }
        },
        "cc591dbb59084d18918e7813faddcf75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd291633b32f40479cc56c47b2fccb83",
            "max": 766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef1c7472f0af42a882c592a1d544f187",
            "value": 766
          }
        },
        "eb136d8de79644769a9d7f28ceba2428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0c581abb3e44eb9603aa61247b9241",
            "placeholder": "​",
            "style": "IPY_MODEL_b56cdae458c946c2a1e747a43af8e78d",
            "value": " 766/766 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "a8c62f1f011d4f9ead05e6885b1099a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6234d222b45a4e6d83ae8af0a7a94293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4355ef7060d460992ff1bbc88f9cbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd291633b32f40479cc56c47b2fccb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef1c7472f0af42a882c592a1d544f187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd0c581abb3e44eb9603aa61247b9241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56cdae458c946c2a1e747a43af8e78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cebd4096dd645c5ae642ee337b54855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22d9b543eb7c4cec9449f11015a690ec",
              "IPY_MODEL_d3f8857ff27d432da47b79b746be1863",
              "IPY_MODEL_7fa28f769f314a41b89b79016b558232"
            ],
            "layout": "IPY_MODEL_ed04b6f9ce404d66b685ff73f42df739"
          }
        },
        "22d9b543eb7c4cec9449f11015a690ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb529214d784a0e896a43c31f4398db",
            "placeholder": "​",
            "style": "IPY_MODEL_3c7f6504ad684014bdbcd6d4516a9c38",
            "value": "Downloading: 100%"
          }
        },
        "d3f8857ff27d432da47b79b746be1863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d37008d94ec4504ad2022b4cc07b23b",
            "max": 990445401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64a0aca260fe42ffb8d86b57154fc06a",
            "value": 990445401
          }
        },
        "7fa28f769f314a41b89b79016b558232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf15c97108824b23a7cf8c3d76867e66",
            "placeholder": "​",
            "style": "IPY_MODEL_ed0ede9b861c432c90fd6fbc559427db",
            "value": " 990M/990M [00:19&lt;00:00, 57.8MB/s]"
          }
        },
        "ed04b6f9ce404d66b685ff73f42df739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb529214d784a0e896a43c31f4398db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7f6504ad684014bdbcd6d4516a9c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d37008d94ec4504ad2022b4cc07b23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a0aca260fe42ffb8d86b57154fc06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf15c97108824b23a7cf8c3d76867e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed0ede9b861c432c90fd6fbc559427db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d4f5868aad3410b9cc8b57089ce2286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b78ef53f7bd4165b0c74d696c33c53a",
              "IPY_MODEL_262a39d60cf3453d940d83da733375fa",
              "IPY_MODEL_5f7da38285fa4262b4c3cdd9a4d18c0c"
            ],
            "layout": "IPY_MODEL_f059a0a8b0d04eed9b91ef9f1aedcfce"
          }
        },
        "8b78ef53f7bd4165b0c74d696c33c53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584bf7f77e72442ebaa76bfbfd7b3e97",
            "placeholder": "​",
            "style": "IPY_MODEL_bc3121c6562b4575a7f4f9c7795050c2",
            "value": "Downloading: 100%"
          }
        },
        "262a39d60cf3453d940d83da733375fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67286d89a0d14b5f89cfe07f24197e5c",
            "max": 1968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a523de9bd1154f01a554d8942e0323e9",
            "value": 1968
          }
        },
        "5f7da38285fa4262b4c3cdd9a4d18c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_085fa56539a5461dbc7632c0dde10add",
            "placeholder": "​",
            "style": "IPY_MODEL_4301bb448d334de4b8944cf32fc0ceff",
            "value": " 1.97k/1.97k [00:00&lt;00:00, 57.0kB/s]"
          }
        },
        "f059a0a8b0d04eed9b91ef9f1aedcfce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "584bf7f77e72442ebaa76bfbfd7b3e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3121c6562b4575a7f4f9c7795050c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67286d89a0d14b5f89cfe07f24197e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a523de9bd1154f01a554d8942e0323e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "085fa56539a5461dbc7632c0dde10add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4301bb448d334de4b8944cf32fc0ceff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7218802398f41b883d622c557fc1eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aeb7832cd10b4633864406ad3676dd28",
              "IPY_MODEL_df5f9e9074004758870b050349e5e13a",
              "IPY_MODEL_3bbcb28c617b4d9b90088e44ab76ecb5"
            ],
            "layout": "IPY_MODEL_72bfd0bc7e2e4c3284a2de729c8637fa"
          }
        },
        "aeb7832cd10b4633864406ad3676dd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f0ac50c58b74e9986a6a09ee21f42f1",
            "placeholder": "​",
            "style": "IPY_MODEL_4a948957624d4b878ec79e033d7f2d75",
            "value": "Downloading: 100%"
          }
        },
        "df5f9e9074004758870b050349e5e13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4fafb3c4ee45939524f8f0723ce6f4",
            "max": 1111492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42bd65f4547d43d692a34af2797bfb6b",
            "value": 1111492
          }
        },
        "3bbcb28c617b4d9b90088e44ab76ecb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850d4d69fa544f21b28ef4ed631399d8",
            "placeholder": "​",
            "style": "IPY_MODEL_8b73aad76da64bb8890a879a911b0365",
            "value": " 1.11M/1.11M [00:00&lt;00:00, 14.8MB/s]"
          }
        },
        "72bfd0bc7e2e4c3284a2de729c8637fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0ac50c58b74e9986a6a09ee21f42f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a948957624d4b878ec79e033d7f2d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b4fafb3c4ee45939524f8f0723ce6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42bd65f4547d43d692a34af2797bfb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "850d4d69fa544f21b28ef4ed631399d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b73aad76da64bb8890a879a911b0365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ab14f0249e34fe18a9b4724fcc362f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_652623c8f09f46cbb666b712c810c92d",
              "IPY_MODEL_9c39064be62b4495a987f944683763ea",
              "IPY_MODEL_92f56f0399a948bc98e6686a0a8f20d9"
            ],
            "layout": "IPY_MODEL_20f88ad66b174e64b99b4b8a7f732ded"
          }
        },
        "652623c8f09f46cbb666b712c810c92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba672779fb04fe1acd7cbb06b67d08a",
            "placeholder": "​",
            "style": "IPY_MODEL_3eed4a8a3dab4c3bbddf065ab3639cc2",
            "value": "Downloading: 100%"
          }
        },
        "9c39064be62b4495a987f944683763ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6a3fec90c164e04993dba84a8cd61cb",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ae83bc209a4e6ebabb7bde856fcbe3",
            "value": 1786
          }
        },
        "92f56f0399a948bc98e6686a0a8f20d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d52c71b6954903b8ac0b2f4071252c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a4a77fcc0d54dd68d68e6ffbd33a391",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 53.9kB/s]"
          }
        },
        "20f88ad66b174e64b99b4b8a7f732ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba672779fb04fe1acd7cbb06b67d08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eed4a8a3dab4c3bbddf065ab3639cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6a3fec90c164e04993dba84a8cd61cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ae83bc209a4e6ebabb7bde856fcbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8d52c71b6954903b8ac0b2f4071252c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4a77fcc0d54dd68d68e6ffbd33a391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}